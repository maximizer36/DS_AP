{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.model_selection import train_test_split as scikit_train_test_split\n",
    "from surprise import Reader, Dataset, accuracy\n",
    "from surprise import KNNBasic, KNNWithMeans, SVD, CoClustering, SlopeOne, SVDpp, NMF, BaselineOnly\n",
    "from surprise.model_selection import KFold, RepeatedKFold, cross_validate, GridSearchCV, LeaveOneOut\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = [\"movie_id\", \"movie_title\" ,\"release_date\",\"video_release_date\", \"IMDb_URL\", \"unknown\", \"Action\", \"Adventure\",\n",
    " \"Animation\", \"Children\\'s\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\",\n",
    " \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    "\n",
    "items = pd.read_csv(\"data/ml-100k/u.item.csv\",sep=\"|\", names=i_cols,encoding='latin-1')\n",
    "\n",
    "movie_dict = dict(zip(items[\"movie_id\"],items[\"movie_title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "all_ratings = data.build_full_trainset().all_ratings()\n",
    "df = pd.DataFrame(columns=[\"uid\", \"iid\", \"rating\"]).astype(int)\n",
    "i = 0\n",
    "for (uid, iid, rating) in all_ratings:\n",
    "    df.loc[i] = [uid, iid, rating]\n",
    "    i = i+1\n",
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = df[\"uid\"].unique()\n",
    "iids = sorted(df[\"iid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_users = 40\n",
    "n_skills = 2\n",
    "sample_size = int(np.ceil((len(uids)/100)*perc_users))\n",
    "\n",
    "random.seed(1)\n",
    "sample = random.sample(population=uids.tolist(),k=sample_size)\n",
    "\n",
    "min_rating = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>378</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137</td>\n",
       "      <td>405</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>582</td>\n",
       "      <td>242</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>582</td>\n",
       "      <td>586</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>867</td>\n",
       "      <td>1079</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>757</td>\n",
       "      <td>309</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>777</td>\n",
       "      <td>368</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>777</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>575</td>\n",
       "      <td>161</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>575</td>\n",
       "      <td>719</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid   iid  rating\n",
       "0    137   378       4\n",
       "1    137   405       5\n",
       "2    582   242       4\n",
       "3    582   586       4\n",
       "4    867  1079       4\n",
       "..   ...   ...     ...\n",
       "749  757   309       5\n",
       "750  777   368       4\n",
       "751  777   113       5\n",
       "752  575   161       4\n",
       "753  575   719       5\n",
       "\n",
       "[754 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout = pd.DataFrame()\n",
    "\n",
    "user_sample = []\n",
    "for uid in sample: \n",
    "    df_subset = df[(df[\"uid\"] == uid) & (df[\"rating\"] >= min_rating)]\n",
    "    # try to get two random high ranking skills (if the employee doesn't have high ranking skills they will be skipped)\n",
    "    try:\n",
    "        holdout_uid = df_subset.sample(n=n_skills,random_state=1)\n",
    "        user_sample.append(uid)\n",
    "        df.drop(holdout_uid.index,inplace=True)\n",
    "        holdout = pd.concat([holdout,holdout_uid],ignore_index=1)\n",
    "    except ValueError:\n",
    "        pass \n",
    "holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 3\n",
    "NUM_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_cv(algo_class,algo_name,param_grid,data,best_model_dict,best_params_dict):\n",
    "    start = time.time()\n",
    "    rmse = np.zeros(NUM_TRIALS)\n",
    "    mse = np.zeros(NUM_TRIALS)\n",
    "    mae = np.zeros(NUM_TRIALS)\n",
    "    models = []\n",
    "    params = []\n",
    "\n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(\"Running CV for model\", algo_name ,\"in Iteration:\", i ,\"at\", time.time()-start)\n",
    "        cv = LeaveOneOut(\n",
    "                        n_splits=NUM_SPLITS,\n",
    "                        random_state=i,\n",
    "                        min_n_ratings=i\n",
    "                    )\n",
    "                        # COMMENT: min_n_ratings -> what's the impact of this parameter? \n",
    "        gs = GridSearchCV(\n",
    "                        algo_class,\n",
    "                        param_grid, \n",
    "                        measures=[\"rmse\",\"mse\",\"mae\"], \n",
    "                        cv=cv,refit=\"rmse\"\n",
    "                    )\n",
    "        gs.fit(data)\n",
    "        rmse[i] = gs.best_score[\"rmse\"]\n",
    "        mse[i] = gs.best_score[\"mse\"]\n",
    "        mae[i] = gs.best_score[\"mae\"]\n",
    "        models.append(gs.best_estimator[\"rmse\"])\n",
    "        params.append(gs.best_params[\"rmse\"])\n",
    "\n",
    "    # hier noch erläutern, warum rmse als ausschlaggebene measure gewählt wird\n",
    "    best_model_dict[algo_name] = models[np.argmin(rmse)]\n",
    "    best_params_dict[algo_name] = params[np.argmin(rmse)]\n",
    "\n",
    "    print(\"Total time: \", (time.time()-start), \"sec.\")\n",
    "    return rmse, mse, mae "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_result(results, name, rmse, mse, mae):\n",
    "    '''\n",
    "    Function adding the results returned by nested_cv to a dataframe. \n",
    "    Results will be aggregated for better comparison. \n",
    "    Parameters: \n",
    "\n",
    "    Output:\n",
    "    results DataFrame containing an additional row\n",
    "    '''\n",
    "    row = pd.DataFrame({\n",
    "        \"name\":name,\n",
    "        \"rmse_mean\":rmse.mean(), \n",
    "        \"rmse_std\":rmse.std(), \n",
    "        \"mse_mean\":mse.mean(), \n",
    "        \"mse_std\":mse.std(), \n",
    "        \"mae_mean\":mae.mean(), \n",
    "        \"mae_std\":mae.std()\n",
    "        },index=[0])\n",
    "    return pd.concat([results,row],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "best_model_dict = {}\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_list = [\n",
    "                (BaselineOnly,\"Baseline\",{\n",
    "                                                \"verbose\":[False]\n",
    "                                    }),\n",
    "                (KNNBasic,\"k-NN\",{\n",
    "                                                \"k\": [20, 40, 60, 80],\n",
    "                                                \"min_k\": [1, 5, 10, 20],\n",
    "                                                \"verbose\":[False]\n",
    "                                    }),\n",
    "                (KNNWithMeans,\"Centered k-NN\",{\n",
    "                                                \"k\": [20, 40, 60, 80],\n",
    "                                                \"min_k\": [1, 5, 10, 20],\n",
    "                                                \"verbose\":[False]\n",
    "                                    }),\n",
    "                (SVD,\"SVD\",{\n",
    "                                                \"n_factors\": [20, 40, 60, 80, 100],\n",
    "                                                \"n_epochs\": [10, 20, 40, 60],\n",
    "                                                \"biased\":[True,False],\n",
    "                                                \"random_state\":[1]\n",
    "                                    }),\n",
    "                # (SVDpp,\"SVD++\",{\n",
    "                #                                 \"n_factors\": [20, 40, 60, 80, 100],\n",
    "                #                                 \"n_epochs\": [10, 20, 40, 60],\n",
    "                #                                 \"random_state\":[1]\n",
    "                #                     }),\n",
    "                # (CoClustering,\"CoClustering\",{\n",
    "                #                                 \"n_cltr_u\": [2, 3, 4],\n",
    "                #                                 \"n_cltr_i\": [2, 3, 4],\n",
    "                #                                 \"n_epochs\":[10, 20, 40, 60]\n",
    "                #                     }),\n",
    "                (SlopeOne,\"SlopeOne\",{\n",
    "                                    }),\n",
    "                (NMF,\"NMF\",{\n",
    "                                                \"n_factors\": [10, 15, 20, 40],\n",
    "                                                \"n_epochs\": [20, 40, 80, 120],\n",
    "                                                \"biased\":[True,False],\n",
    "                                                \"random_state\":[1]\n",
    "                                    })\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in algo_list:\n",
    "    rmse, mse, mae = gridsearch_cv(algo[0],algo[1],algo[2],data,best_model_dict,best_params_dict)\n",
    "    results = add_result(results,algo[1],rmse, mse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_factors= 40, n_epochs = 120, biased = False, random_state= 1)\n",
    "#model = best_model_dict[\"SVD++\"]\n",
    "#model = SVDpp(n_factors = 40, n_epochs= 60, random_state=1)\n",
    "trainset = data.build_full_trainset()\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = {}\n",
    "    \n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        try:\n",
    "                top_n[uid].append((iid, est))\n",
    "        except KeyError:\n",
    "                top_n[uid] = [(iid, est)]\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recoms_for_employee(emp_id,n):\n",
    "    df_subset = df_rated[df_rated[\"person\"] == 233]\n",
    "    recom_df = pd.DataFrame()\n",
    "    recom_df[\"skill\"] = skills\n",
    "    recom_df[\"person\"] = emp_id\n",
    "    employee_ratings = np.zeros(len(skills))\n",
    "    for i in range(0,len(skills)): \n",
    "        try:\n",
    "            employee_ratings[i] = df_subset[df_subset[\"skill\"] == skills[i]][\"rating\"]\n",
    "        except ValueError:\n",
    "            employee_ratings[i] = np.nan\n",
    "    recom_df[\"rating\"] = employee_ratings\n",
    "    recom_df = recom_df[[\"person\",\"skill\",\"rating\"]]\n",
    "    #return recom_df.to_numpy()\n",
    "    preds = model.test(recom_df.to_numpy())\n",
    "    return get_top_n(preds,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.test(trainset.build_anti_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n(preds, n=10)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "recommendations = pd.DataFrame()\n",
    "\n",
    "for uid, user_ratings in top_n.items():\n",
    "    recom = pd.DataFrame(index=[uid],data=[[iid for (iid, _) in user_ratings]])\n",
    "    #print([iid for (iid, _) in user_ratings])\n",
    "    recommendations = pd.concat([recommendations,recom])\n",
    "\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recoms_for_employee(233,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_holdout_occurence(holdout,recommendations):\n",
    "    score = 0 \n",
    "    for emp in holdout[\"person\"].unique():\n",
    "        skills = holdout[holdout[\"person\"] == emp][\"skill\"].values\n",
    "        for skill in skills:\n",
    "            if skill in recommendations.iloc[12].to_list():\n",
    "                score = score + 1\n",
    "    return score/len(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_holdout_occurence(holdout,recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recoms_for_new_employee(new_id,skilldict,model):\n",
    "\n",
    "    all_ids = df_rated[\"person\"].unique()\n",
    "    all_skills = df_rated[\"skill\"].unique()\n",
    "\n",
    "    if new_id in all_ids:\n",
    "        return \"Error: ID already taken. Please choose a different ID an try again.\"\n",
    "    for skill in skilldict.keys():\n",
    "        if skill not in all_skills:\n",
    "            return \"Skill \" + skill + \" not in database.\"\n",
    "            # COMMENT: this is only a placeholder. For ideas on how to handle new skills, see \"HOW TO HANDLE NEW SKILL\" section \n",
    "\n",
    "    new_test = []\n",
    "    for skill in all_skills:\n",
    "        try:\n",
    "            skill_rating = skilldict[skill]\n",
    "            new_test.append((new_id,skill,skill_rating))\n",
    "        except KeyError:\n",
    "            new_test.append((new_id,skill,np.nan))\n",
    "    \n",
    "    predictions = model.test(new_test)\n",
    "\n",
    "    return get_top_n(predictions, n=10)[new_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ds_ap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52cefc3a9eff3ff32f2531cecf7f574c5eb7023f21571ad3a673d9838121c504"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
