{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS - Application Project <br>\n",
    "# Developement of a Recommender System for Employee Skills - Binary Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "#import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from implicit.evaluation import train_test_split\n",
    "# from implicit.nearest_neighbours import (\n",
    "#     normalize,\n",
    "#     bm25_weight\n",
    "# )\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse\n",
    "# from implicit.lmf import LogisticMatrixFactorization\n",
    "from implicit.evaluation import precision_at_k,mean_average_precision_at_k, ndcg_at_k\n",
    "from random import shuffle\n",
    "import itertools\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>skill</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Windows NT/2000/XP</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>MAC OS X</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Windows 7</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>Windows 8</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>iOS</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person               skill        category\n",
       "0      12  Windows NT/2000/XP  Betriebssystem\n",
       "1      12            MAC OS X  Betriebssystem\n",
       "2      12           Windows 7  Betriebssystem\n",
       "3      12           Windows 8  Betriebssystem\n",
       "4      12                 iOS  Betriebssystem"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/person-skills_2022-06-27.csv\",sep=\";\") \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame that assigns a category to every skill:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Windows NT/2000/XP</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC OS X</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Windows 7</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Windows 8</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iOS</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                skill        category\n",
       "0  Windows NT/2000/XP  Betriebssystem\n",
       "1            MAC OS X  Betriebssystem\n",
       "2           Windows 7  Betriebssystem\n",
       "3           Windows 8  Betriebssystem\n",
       "4                 iOS  Betriebssystem"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categories = df[[\"skill\",\"category\"]].drop_duplicates()\n",
    "data_categories.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring various aiding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONS = df[\"person\"].unique()\n",
    "SKILLS = sorted(df[\"skill\"].unique())\n",
    "CATEGORIES = df[\"category\"].unique()\n",
    "employee_dict = {}\n",
    "for n in range(0,len(PERSONS)):\n",
    "    employee_dict[n] = PERSONS[n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning: <br> <br>\n",
    "In order to evaluate the effect of inputmatrices  (APPENDIX XY) with a different level of sparsity, it is reasonable to introduce a function, that allows us to drop rare skills, that occur less than x times in the dataset. Sparsity is here defined as the relationship of ones and zeros inside a user-item-matrix, where ones represent, that a user is proficient in a certain skill. On the other hand a zero inside a user-item-matrix represents that a user has no knowledge about cetrain skill. Accordingly rare skills are responsible for many zeros inside the user-item-matrix. By dropping these rare skills the total amount of zeros is reduced and therefore the matrix becomes less sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rare_skills(data:pd.DataFrame, n:int):\n",
    "    '''\n",
    "    Function to determine all skills which occur less than n times in a given dataset.\n",
    "    Dataset must be a pandas Dataframe with columns: person, skill.\n",
    "    ----------\n",
    "    Parameters: \n",
    "    data : pd.DataFrame\n",
    "    The data in which rare skills are to be determined. \n",
    "    n : int \n",
    "    The threshold frequency.\n",
    "    ----------\n",
    "    Returns: \n",
    "    List of skills occuring less than n times in dataset.\n",
    "    '''\n",
    "    skill_frequency = {}\n",
    "    for skill in data[\"skill\"].unique():\n",
    "        skill_frequency[skill] = data[data[\"skill\"] == skill][\"person\"].nunique()\n",
    "\n",
    "    return [s for s,f in skill_frequency.items() if f <= n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***for insights in why no skills are dropped please refer to Appendix I***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_skills = get_rare_skills(df,0)\n",
    "df = df[~df[\"skill\"].isin(rare_skills)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24586, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implicit library works with sparse-matrices. In order to transform a dataset into its sparse representation the dataset must be restructured in the following way: <br>\n",
    "* Each row represents a user\n",
    "* Each column represents a item/skill\n",
    "* Each entity represents whether a user is proficient in a skill or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>skill</th>\n",
       "      <th>.NET Compact Framework</th>\n",
       "      <th>.NET Core</th>\n",
       "      <th>.NET Framework</th>\n",
       "      <th>3D-Modellierung</th>\n",
       "      <th>ABAP</th>\n",
       "      <th>ADO.NET</th>\n",
       "      <th>AIX</th>\n",
       "      <th>ARIS</th>\n",
       "      <th>ARIS ITArchitect</th>\n",
       "      <th>AS400</th>\n",
       "      <th>...</th>\n",
       "      <th>ramda.js</th>\n",
       "      <th>ranorex</th>\n",
       "      <th>samba</th>\n",
       "      <th>script.aculo.us</th>\n",
       "      <th>varnish</th>\n",
       "      <th>visual paradigm</th>\n",
       "      <th>vnc</th>\n",
       "      <th>vs code</th>\n",
       "      <th>xHTML</th>\n",
       "      <th>xtCommerce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userids</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "skill    .NET Compact Framework  .NET Core  .NET Framework  3D-Modellierung  \\\n",
       "userids                                                                       \n",
       "0                             0          0               0                0   \n",
       "1                             0          0               1                0   \n",
       "2                             0          0               0                1   \n",
       "3                             0          0               0                0   \n",
       "4                             0          0               0                0   \n",
       "...                         ...        ...             ...              ...   \n",
       "399                           0          0               0                0   \n",
       "400                           0          0               0                0   \n",
       "401                           0          0               0                0   \n",
       "402                           0          1               1                0   \n",
       "403                           0          0               0                0   \n",
       "\n",
       "skill    ABAP  ADO.NET  AIX  ARIS  ARIS ITArchitect  AS400  ...  ramda.js  \\\n",
       "userids                                                     ...             \n",
       "0           0        0    0     0                 0      0  ...         0   \n",
       "1           0        1    0     0                 0      0  ...         0   \n",
       "2           0        0    0     0                 0      0  ...         0   \n",
       "3           0        0    0     0                 0      0  ...         0   \n",
       "4           0        0    0     0                 0      0  ...         0   \n",
       "...       ...      ...  ...   ...               ...    ...  ...       ...   \n",
       "399         0        0    0     0                 0      0  ...         0   \n",
       "400         0        0    0     0                 0      0  ...         0   \n",
       "401         0        0    0     0                 0      0  ...         0   \n",
       "402         0        0    0     0                 0      0  ...         0   \n",
       "403         1        0    0     0                 0      0  ...         0   \n",
       "\n",
       "skill    ranorex  samba  script.aculo.us  varnish  visual paradigm  vnc  \\\n",
       "userids                                                                   \n",
       "0              0      0                0        0                0    0   \n",
       "1              0      0                0        0                0    0   \n",
       "2              0      0                0        0                0    0   \n",
       "3              0      0                0        0                0    0   \n",
       "4              0      0                0        0                0    0   \n",
       "...          ...    ...              ...      ...              ...  ...   \n",
       "399            0      0                0        0                0    0   \n",
       "400            0      0                0        0                0    0   \n",
       "401            0      0                0        0                0    0   \n",
       "402            0      0                0        0                0    0   \n",
       "403            0      0                0        0                1    0   \n",
       "\n",
       "skill    vs code  xHTML  xtCommerce  \n",
       "userids                              \n",
       "0              0      0           0  \n",
       "1              0      0           0  \n",
       "2              0      1           0  \n",
       "3              0      0           0  \n",
       "4              0      0           0  \n",
       "...          ...    ...         ...  \n",
       "399            0      0           0  \n",
       "400            0      0           0  \n",
       "401            0      0           0  \n",
       "402            0      0           0  \n",
       "403            0      0           0  \n",
       "\n",
       "[404 rows x 734 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a user-item matrix\n",
    "df[\"count\"] = 1\n",
    "data_skills = df.pivot_table('count', index='person', columns=\"skill\").fillna(0).astype(int).reset_index(drop=True)\n",
    "#Set the index name = \"userid\"\n",
    "data_skills.index.names = [\"userids\"]\n",
    "data_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the matrix can be transformed into its sparse representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_skills_csr = scipy.sparse.csr_matrix(data_skills.values)\n",
    "type(data_skills_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data:\n",
    "\n",
    "In the following a function will be introduced that performs different normalization techniques on the dataset. The idea behind **row normalization** in its simples form (here: implicit.nearest_neighbours.normalizeI) is, that a certain skill is more valuable for a user with a small skill set than for a user with a very large skill set. The following toy example will demonstrate this effect:\n",
    "* Lets assume, that we want to investigate how important the skill \"Python\" is for user A and user B.\n",
    "* The skill set of user A includes 10 different skills.\n",
    "* The skill set of user B includes 100 different skills\n",
    "* In our unnormalized dataset the importance of Python would be represented by a 1 for both users - no matter how large their skill set is. Hence the importance for both users is equal.\n",
    "* However on the normalized dataset importance of \"Python\" would be larger for user A than for user B, because of the different size of their skillset.\n",
    "\n",
    "While normalization only respects a single skill set at once in its calculation, the techniques **TF-IDF** and **bm25** techniques expand the idea of measureing skill importance by considering all skill sets in their computation. <br>\n",
    "\n",
    "***For more detailed insights in these techniques please have a look at our documentation.*** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_grid  = {\n",
    "            'K1': [50,100,120]#,20,50,100\n",
    "            ,'B': [0.75,1] # 0.4,0.8,1\n",
    "            }\n",
    "\n",
    "# param_grid_bm25  = {'K1': [2,50,100], #2,20,50,100\n",
    "#                     'B': [ 0.4,0.8,1] # 0.4,0.8,1\n",
    "#                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer (data:csr_matrix ,param_grid:dict):\n",
    "    '''\n",
    "    Function to perform different normalization techniques on a user-item-matrix, where the users are represented in the rows and the items in the columns.\n",
    "    The following techniques will be performed:\n",
    "    - Raw (no normalization technique)\n",
    "    - Normalization\n",
    "    - tfidf\n",
    "    - bm25\n",
    "    ----------\n",
    "    Parameters: \n",
    "    data : csr_matrix\n",
    "    The data in sparse csr format which will be normalized. \n",
    "    param_grid : dict \n",
    "    A dictonary that holds different values for the parameters of implicit's bm25_weight.\n",
    "    The dictonary must consist of the following key value pairs:\n",
    "    - K1 : list of floats\n",
    "    - B : list of floats\n",
    "    ----------\n",
    "    Returns: \n",
    "    - List holding the transformed dataset.\n",
    "    - Pandas DataFrame, where each row provides information about the performed transformation. \n",
    "      The first row provides information about the first element in the returned list, the second row about the second element in the returned list and so on. \n",
    "    '''\n",
    "    data_representations = ['Raw','Normalized', 'tfidf', 'bm25']    \n",
    "    df_list = []\n",
    "    data_list = []\n",
    "\n",
    "\n",
    "    for representation in data_representations:\n",
    "        df = pd.DataFrame(columns = ['data_representations', 'K1', 'B'])\n",
    "\n",
    "        if representation == 'bm25':\n",
    "            keys, values = zip(*param_grid.items())\n",
    "            for c,v in enumerate(itertools.product(*values)):\n",
    "                params = dict(zip(keys, v))\n",
    "                \n",
    "                #############\n",
    "                # Initiate df for the parameter combination\n",
    "                #############\n",
    "                df = pd.DataFrame()\n",
    "                df = pd.DataFrame(params, index =  [c])\n",
    "                df[\"data_representations\"] = [representation]\n",
    "                df_list.append(df)\n",
    "\n",
    "                #############\n",
    "                # Add key value pair to the dictonary and initiate the bm25_weight function for every parameter combination\n",
    "                #############\n",
    "                params['X'] = data\n",
    "                data_transf = implicit.nearest_neighbours.bm25_weight(**params)\n",
    "                data_list.append(data_transf)\n",
    "        else:\n",
    "\n",
    "            match representation:\n",
    "                case 'Normalized':\n",
    "                    data_transf = implicit.nearest_neighbours.normalize(data)\n",
    "                case 'tfidf':\n",
    "                    data_transf = implicit.nearest_neighbours.tfidf_weight(data)\n",
    "                case 'Raw':\n",
    "                    data_transf = data\n",
    "            df[\"data_representations\"] = [representation]\n",
    "            df[\"K1\"] = np.nan\n",
    "            df[\"B\"] = np.nan  \n",
    "            df_list.append(df)\n",
    "            data_list.append(data_transf)\n",
    "\n",
    "    return data_list, pd.concat(df_list).reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_representations</th>\n",
       "      <th>K1</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bm25</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bm25</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bm25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bm25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_representations     K1     B\n",
       "0                  Raw    NaN   NaN\n",
       "1           Normalized    NaN   NaN\n",
       "2                tfidf    NaN   NaN\n",
       "3                 bm25   50.0  0.75\n",
       "4                 bm25   50.0  1.00\n",
       "5                 bm25  100.0  0.75\n",
       "6                 bm25  100.0  1.00\n",
       "7                 bm25  120.0  0.75\n",
       "8                 bm25  120.0  1.00"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, df = normalizer(data_skills_csr, bm25_grid)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit Library - Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section different recommender systems will be compared to each other. The comparison will be organized through a gridsearch. Conventionally a gridsearch is processed in combination with a cross validation.The goal of the gridsearch is to find the best possible parametrization (within the grid) for the model. The goal of the cross-validation is to reduce the impact of randomness on the model evaluation, which occurs when the data is splitted into train and test data. <br>\n",
    "\n",
    "Since the algorithms of the implicit library perform different matrix factorization methods, the data can not be splitted into k-subsets during the cross-validation. A traditional KFold cross-validation is impractical for models, that use matrix factorization, because they need to decompose the whole dataset at once in order to make recommendations for every user and item within the dataset. The model could not make recommendations for users, if they are excluded in the traingsdata. <br>\n",
    "\n",
    "Therefore a different cross-validation scheme will be introduced to reduce the effect of randomness on the model results. The cross-validation in our setup is organized by performing the **train.test-split of the implicit** library 5 times with a different random state on each iteration. This train-test-split does not exclude users from the trainingsdata. Instead the split is performed on user-item-interactions. Hence the traingsdata still includes every user and every item, but not every user-item-interaction. Metaphorically speaking the train-test-split replaces interaction (e.g. ones) with zeros. The replaced interactions are retained in the testdata. The model is evaluated on how well it can replicate the retrained user-item-interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_cv_implicit(data:csr_matrix, algorithm, param_grid: dict, k:int):\n",
    "    '''\n",
    "    This function will call the \"normalizer\" function in order to produce different transformations of the inserted user-item-matrix. \n",
    "    For more details about the transformationprocess check the documentation of the \"normalizer\" function.\n",
    "    For each version of the user-item-matrix a gridsearch and a cross validation will be executed.\n",
    "    This function uses the train-test-split of the implicit library to perform the cross validation.\n",
    "    This train-test-split does not exclude whole users from the training set,but user-item-interactions. \n",
    "    The model is evaluated on how well it predicts the user-item-interactions that were excluded from the training set. \n",
    "    ----------\n",
    "    Parameters: \n",
    "    data : csr_matrix\n",
    "    The data in sparse csr format which will be normalized. \n",
    "    algorithm : \n",
    "    A algorithm from the implicit library.\n",
    "    param_grid : dict \n",
    "    A dictonary that holds different values for the parameters of the algorithm.\n",
    "    k : int\n",
    "    The number of recommendations that will be made for each user in order to evaluate the model.\n",
    "    ----------\n",
    "    Returns: \n",
    "    - Pandas DataFrame that contains the results for each parametrization of the algorithm.\n",
    "    '''\n",
    "    df_result = pd.DataFrame()\n",
    "    \n",
    "    datasets, results = normalizer(data, bm25_grid)\n",
    "\n",
    "    \n",
    "    for i,data_rep in enumerate(datasets):\n",
    "        row = results.loc[i].to_frame().T\n",
    "\n",
    "        #############\n",
    "        # Create tuples of my gird\n",
    "        # E.g. keys = ('factors','alpha') ; values = ([10,20],[1])\n",
    "        #############\n",
    "        keys, values = zip(*param_grid.items())\n",
    "        for val in itertools.product(*values):\n",
    "\n",
    "            #############\n",
    "            # This loop produces every possible combination of the hyperparameters as a dictonary\n",
    "            #############\n",
    "            params = dict(zip(keys, val))\n",
    "            this_model = copy.deepcopy(algorithm)\n",
    "            df_params = pd.DataFrame(params, index =  [i])\n",
    "    \n",
    "\n",
    "            for hyper_p,hyper_v  in params.items():\n",
    "                #############\n",
    "                # This loop unpacks the diconary by each parameter and initiates the model for each hpyerparameter of the corresponding dictonary\n",
    "                #############\n",
    "                setattr(this_model, hyper_p, hyper_v)\n",
    "\n",
    "            ############\n",
    "            # lists to store the results after each train_test_split under different random seed (c.p)\n",
    "            ############\n",
    "            p_train_test_results = np.zeros(NUM_TRIALS)\n",
    "            map_train_test_results = np.zeros(NUM_TRIALS)\n",
    "            ndcg_train_test_results = np.zeros(NUM_TRIALS)\n",
    "\n",
    "\n",
    "            for seed in range(NUM_TRIALS):\n",
    "                #############\n",
    "                # Initiate the train_test_split\n",
    "                #############\n",
    "                train_mat, test_mat = implicit.evaluation.train_test_split(data_rep, train_percentage =  0.8, random_state = seed)\n",
    "                this_model.fit(train_mat,show_progress=False)\n",
    "\n",
    "                #############\n",
    "                # measure evaluation metrixs for each possible hyperparameter combination\n",
    "                #############\n",
    "                p_at_k =  precision_at_k(this_model, train_user_items=train_mat, test_user_items=test_mat, K=k ,show_progress=False)\n",
    "                map_at_k = mean_average_precision_at_k(this_model, train_user_items=train_mat, test_user_items=test_mat, K=k,show_progress=False)\n",
    "                var_ndcg_at_k = ndcg_at_k(this_model, train_user_items=train_mat, test_user_items=test_mat, K=k,show_progress=False)\n",
    "\n",
    "\n",
    "                #############\n",
    "                # To list\n",
    "                #############\n",
    "                p_train_test_results[seed] = p_at_k\n",
    "                map_train_test_results[seed] = map_at_k \n",
    "                ndcg_train_test_results[seed] = var_ndcg_at_k\n",
    "\n",
    "            #############\n",
    "            # Create columns to store the scores for each hyperparameter combination after 5 different train_test_splits\n",
    "            #############\n",
    "            df_params[\"precision_at_k\"] = np.mean(p_train_test_results)\n",
    "            df_params[\"map_at_k\"]  = np.mean(map_train_test_results)\n",
    "            df_params[\"ndcg_at_k\"] = np.mean(ndcg_train_test_results)\n",
    "\n",
    "            df_result = pd.concat([df_result,pd.concat([row,df_params],axis = 1)],axis = 0,ignore_index=True)\n",
    "\n",
    "    return  df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameter-grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_grid = {\n",
    "              'factors': [3,6,7,8,9,10,15],\n",
    "              'regularization': [0.005,0.01,0.02],\n",
    "              'iterations' : [10,15,30], \n",
    "              'alpha': [1] \n",
    "              }  \n",
    "# als_grid = {\n",
    "            #   'factors': [1,2],\n",
    "            #   'regularization': [0.005],\n",
    "            #   'iterations' : [15], \n",
    "            #   'alpha': [1] \n",
    "            #   }          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the Alternating Least Squares algorithm from the implicit library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = implicit.als.AlternatingLeastSquares(random_state= 42)\n",
    "# results_als = gridsearch_cv_implicit(data_skills_csr, model, als_grid, k = 5)\n",
    "# results_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    40\n",
       "data_representations         Raw\n",
       "K1                           NaN\n",
       "B                            NaN\n",
       "factors                        9\n",
       "regularization              0.01\n",
       "iterations                    15\n",
       "alpha                          1\n",
       "precision_at_k          0.571333\n",
       "map_at_k                0.462859\n",
       "ndcg_at_k                0.56003\n",
       "Name: 40, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results_als.to_csv(\"results_als.csv\")\n",
    "results_als = pd.read_csv(\"results_als.csv\")\n",
    "results_als.iloc[results_als.precision_at_k.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the parametrization of the model with the best precision at k score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    40\n",
       "data_representations         Raw\n",
       "K1                           NaN\n",
       "B                            NaN\n",
       "factors                        9\n",
       "regularization              0.01\n",
       "iterations                    15\n",
       "alpha                          1\n",
       "precision_at_k          0.571333\n",
       "map_at_k                0.462859\n",
       "ndcg_at_k                0.56003\n",
       "Name: 40, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_als = results_als.iloc[results_als.precision_at_k.idxmax()]\n",
    "best_model_als"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Matrix Factorization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameter-grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmf_grid = {\n",
    "              'factors': [3,6,7,8,9,10,15],\n",
    "              'regularization': [0.005,0.01,0.02],\n",
    "              'iterations' : [10,15,30], \n",
    "              'alpha': [1] \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the Logistic Matrix Factorization algorithm from the implicit library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = implicit.lmf.LogisticMatrixFactorization(random_state= 42)\n",
    "# results_lmf= gridsearch_cv_implicit(data_skills_csr, algorithm = model,param_grid =  lmf_grid, k = 5)\n",
    "# results_lmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_representations</th>\n",
       "      <th>K1</th>\n",
       "      <th>B</th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iterations</th>\n",
       "      <th>alpha</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>map_at_k</th>\n",
       "      <th>ndcg_at_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296645</td>\n",
       "      <td>0.199434</td>\n",
       "      <td>0.284637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317075</td>\n",
       "      <td>0.214490</td>\n",
       "      <td>0.303739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310359</td>\n",
       "      <td>0.209155</td>\n",
       "      <td>0.297752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.301123</td>\n",
       "      <td>0.205383</td>\n",
       "      <td>0.291394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.318851</td>\n",
       "      <td>0.213527</td>\n",
       "      <td>0.303988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191443</td>\n",
       "      <td>0.105793</td>\n",
       "      <td>0.179151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.172647</td>\n",
       "      <td>0.097386</td>\n",
       "      <td>0.163505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178262</td>\n",
       "      <td>0.099788</td>\n",
       "      <td>0.169277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188320</td>\n",
       "      <td>0.101774</td>\n",
       "      <td>0.173134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.170986</td>\n",
       "      <td>0.096610</td>\n",
       "      <td>0.162668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    data_representations     K1    B  factors  regularization  iterations  \\\n",
       "0                    Raw    NaN  NaN        3           0.005          10   \n",
       "1                    Raw    NaN  NaN        3           0.005          15   \n",
       "2                    Raw    NaN  NaN        3           0.005          30   \n",
       "3                    Raw    NaN  NaN        3           0.010          10   \n",
       "4                    Raw    NaN  NaN        3           0.010          15   \n",
       "..                   ...    ...  ...      ...             ...         ...   \n",
       "562                 bm25  120.0  1.0       15           0.010          15   \n",
       "563                 bm25  120.0  1.0       15           0.010          30   \n",
       "564                 bm25  120.0  1.0       15           0.020          10   \n",
       "565                 bm25  120.0  1.0       15           0.020          15   \n",
       "566                 bm25  120.0  1.0       15           0.020          30   \n",
       "\n",
       "     alpha  precision_at_k  map_at_k  ndcg_at_k  \n",
       "0        1        0.296645  0.199434   0.284637  \n",
       "1        1        0.317075  0.214490   0.303739  \n",
       "2        1        0.310359  0.209155   0.297752  \n",
       "3        1        0.301123  0.205383   0.291394  \n",
       "4        1        0.318851  0.213527   0.303988  \n",
       "..     ...             ...       ...        ...  \n",
       "562      1        0.191443  0.105793   0.179151  \n",
       "563      1        0.172647  0.097386   0.163505  \n",
       "564      1        0.178262  0.099788   0.169277  \n",
       "565      1        0.188320  0.101774   0.173134  \n",
       "566      1        0.170986  0.096610   0.162668  \n",
       "\n",
       "[567 rows x 10 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results_lmf.to_csv('results_lmf.csv')\n",
    "results_lmf = pd.read_csv('results_lmf.csv', index_col = 0)\n",
    "results_lmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the parametrization of the model with the best precision at k score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_representations    Normalized\n",
       "K1                             NaN\n",
       "B                              NaN\n",
       "factors                          6\n",
       "regularization                0.02\n",
       "iterations                      15\n",
       "alpha                            1\n",
       "precision_at_k            0.346307\n",
       "map_at_k                  0.233204\n",
       "ndcg_at_k                 0.331538\n",
       "Name: 79, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_lmf = results_lmf.iloc[results_lmf.precision_at_k.idxmax()]\n",
    "best_model_lmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameter-grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_grid = {\n",
    "              'factors': [3,6,7,8,9,10,15],\n",
    "              'regularization': [0.005,0.01,0.02],\n",
    "              'iterations' : [10,15,30], \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the Logisitic Matrix Factorization algorithm from the implicit library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = implicit.bpr.BayesianPersonalizedRanking(random_state= 42)\n",
    "# results_bpr= gridsearch_cv_implicit(data_skills_csr, algorithm = model,param_grid =  bpr_grid, k = 5)\n",
    "# results_bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_representations</th>\n",
       "      <th>K1</th>\n",
       "      <th>B</th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iterations</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>map_at_k</th>\n",
       "      <th>ndcg_at_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>0.474473</td>\n",
       "      <td>0.368146</td>\n",
       "      <td>0.460840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>0.466369</td>\n",
       "      <td>0.358393</td>\n",
       "      <td>0.452068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>0.426161</td>\n",
       "      <td>0.321278</td>\n",
       "      <td>0.419129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.475401</td>\n",
       "      <td>0.368810</td>\n",
       "      <td>0.461495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>0.467553</td>\n",
       "      <td>0.359157</td>\n",
       "      <td>0.452836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>0.493787</td>\n",
       "      <td>0.388139</td>\n",
       "      <td>0.483068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.375649</td>\n",
       "      <td>0.478297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>10</td>\n",
       "      <td>0.471583</td>\n",
       "      <td>0.368724</td>\n",
       "      <td>0.460327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>15</td>\n",
       "      <td>0.485652</td>\n",
       "      <td>0.381570</td>\n",
       "      <td>0.475572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>bm25</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>0.476397</td>\n",
       "      <td>0.369661</td>\n",
       "      <td>0.471472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    data_representations     K1    B  factors  regularization  iterations  \\\n",
       "0                    Raw    NaN  NaN        3           0.005          10   \n",
       "1                    Raw    NaN  NaN        3           0.005          15   \n",
       "2                    Raw    NaN  NaN        3           0.005          30   \n",
       "3                    Raw    NaN  NaN        3           0.010          10   \n",
       "4                    Raw    NaN  NaN        3           0.010          15   \n",
       "..                   ...    ...  ...      ...             ...         ...   \n",
       "562                 bm25  120.0  1.0       15           0.010          15   \n",
       "563                 bm25  120.0  1.0       15           0.010          30   \n",
       "564                 bm25  120.0  1.0       15           0.020          10   \n",
       "565                 bm25  120.0  1.0       15           0.020          15   \n",
       "566                 bm25  120.0  1.0       15           0.020          30   \n",
       "\n",
       "     precision_at_k  map_at_k  ndcg_at_k  \n",
       "0          0.474473  0.368146   0.460840  \n",
       "1          0.466369  0.358393   0.452068  \n",
       "2          0.426161  0.321278   0.419129  \n",
       "3          0.475401  0.368810   0.461495  \n",
       "4          0.467553  0.359157   0.452836  \n",
       "..              ...       ...        ...  \n",
       "562        0.493787  0.388139   0.483068  \n",
       "563        0.483000  0.375649   0.478297  \n",
       "564        0.471583  0.368724   0.460327  \n",
       "565        0.485652  0.381570   0.475572  \n",
       "566        0.476397  0.369661   0.471472  \n",
       "\n",
       "[567 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results_bpr.to_csv('results_bpr.csv')\n",
    "results_bpr = pd.read_csv('results_bpr.csv', index_col = 0)\n",
    "results_bpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the parametrization of the model with the best precision at k score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_representations        bm25\n",
       "K1                         120.0\n",
       "B                            1.0\n",
       "factors                       15\n",
       "regularization             0.005\n",
       "iterations                    15\n",
       "precision_at_k          0.499674\n",
       "map_at_k                0.392897\n",
       "ndcg_at_k               0.488486\n",
       "Name: 559, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_bpr = results_bpr.iloc[results_bpr.precision_at_k.idxmax()]\n",
    "best_model_bpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the best models across the algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will identify the best model over all algortihms, which were used.\n",
    "Therefore two dictonaries are created.\n",
    "\n",
    "The dictonary \"comparision_dict\" is used to compare the results of the best performing models of each algorithm.\n",
    "\n",
    "The dictonary \"best_dict\" is then used to determine the best model across all different algortihms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data_representation</th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>precision_at_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>als</td>\n",
       "      <td>Raw</td>\n",
       "      <td>9</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.571333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lmf</td>\n",
       "      <td>Normalized</td>\n",
       "      <td>6</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.346307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bpr</td>\n",
       "      <td>bm25</td>\n",
       "      <td>15</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.499674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model data_representation  factors  regularization  precision_at_k\n",
       "0   als                 Raw        9           0.010        0.571333\n",
       "1   lmf          Normalized        6           0.020        0.346307\n",
       "2   bpr                bm25       15           0.005        0.499674"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_dict= {\n",
    "            'model': ['als','lmf','bpr']\n",
    "            ,'data_representation': [best_model_als.data_representations, best_model_lmf.data_representations, best_model_bpr.data_representations]\n",
    "            ,'factors': [best_model_als.factors, best_model_lmf.factors, best_model_bpr.factors]\n",
    "            ,'regularization': [best_model_als.regularization, best_model_lmf.regularization, best_model_bpr.regularization]    \n",
    "            ,'precision_at_k': [best_model_als.precision_at_k, best_model_lmf.precision_at_k, best_model_bpr.precision_at_k]\n",
    "            }\n",
    "            \n",
    "best_dict = {\n",
    "            'als':best_model_als\n",
    "            ,'lmf':best_model_lmf\n",
    "            ,'bpr':best_model_bpr\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "best_model_comparison = pd.DataFrame(comparison_dict)\n",
    "best_model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    40\n",
       "data_representations         Raw\n",
       "K1                           NaN\n",
       "B                            NaN\n",
       "factors                        9\n",
       "regularization              0.01\n",
       "iterations                    15\n",
       "alpha                          1\n",
       "precision_at_k          0.571333\n",
       "map_at_k                0.462859\n",
       "ndcg_at_k                0.56003\n",
       "Name: 40, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_key = best_model_comparison.iloc[best_model_comparison.precision_at_k.idxmax()][\"model\"]\n",
    "best_model = best_dict[best_key]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the representation of the data, that performed the best (raw, normalized, tf-idf or bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_bm25  = { 'X': data_skills_csr,\n",
    "                    'K1': best_model[\"K1\"], \n",
    "                    'B': best_model[\"B\"] \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_representation_dict  = {'Raw':data_skills_csr\n",
    "                            ,'Normalized':  implicit.nearest_neighbours.normalize(data_skills_csr)\n",
    "                            , 'tfidf':implicit.nearest_neighbours.tfidf_weight(data_skills_csr)\n",
    "                            , 'bm25':implicit.nearest_neighbours.bm25_weight(**best_grid_bm25)\n",
    "                            }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_data = data_representation_dict[best_model[\"data_representations\"]]\n",
    "best_data = best_data.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate a train-test-split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat, test_mat = implicit.evaluation.train_test_split(best_data, train_percentage =  0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mimplicit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAlternatingLeastSquares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfactors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mregularization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[1;34m'numpy.float32'\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0muse_native\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0muse_cg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0muse_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcalculate_training_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_threads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Alternating Least Squares\n",
      "\n",
      "A Recommendation Model based off the algorithms described in the paper 'Collaborative\n",
      "Filtering for Implicit Feedback Datasets' with performance optimizations described in\n",
      "'Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative\n",
      "Filtering.'\n",
      "\n",
      "This factory function switches between the cpu and gpu implementations found in\n",
      "implicit.cpu.als.AlternatingLeastSquares and implicit.gpu.als.AlternatingLeastSquares\n",
      "depending on the use_gpu flag.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "factors : int, optional\n",
      "    The number of latent factors to compute\n",
      "regularization : float, optional\n",
      "    The regularization factor to use\n",
      "dtype : data-type, optional\n",
      "    Specifies whether to generate 64 bit or 32 bit floating point factors\n",
      "use_native : bool, optional\n",
      "    Use native extensions to speed up model fitting\n",
      "use_cg : bool, optional\n",
      "    Use a faster Conjugate Gradient solver to calculate factors\n",
      "use_gpu : bool, optional\n",
      "    Fit on the GPU if available, default is to run on GPU only if available\n",
      "iterations : int, optional\n",
      "    The number of ALS iterations to use when fitting data\n",
      "calculate_training_loss : bool, optional\n",
      "    Whether to log out the training loss at each iteration\n",
      "num_threads : int, optional\n",
      "    The number of threads to use for fitting the model. This only\n",
      "    applies for the native extensions. Specifying 0 means to default\n",
      "    to the number of cores on the machine.\n",
      "random_state : int, RandomState or None, optional\n",
      "    The random state for seeding the initial item and user factors.\n",
      "    Default is None.\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\admin\\envs\\ds_ap\\lib\\site-packages\\implicit\\als.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "implicit.als.AlternatingLeastSquares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_best_model(key:str , model_params:pd.Series, data:csr_matrix):\n",
    "    '''\n",
    "    This function initiates a model based on the algorithm, that is represented by the parameter 'key'.\n",
    "    The model will be initiated with the given parameters and will be fitted on the given data. \n",
    "    ----------\n",
    "    Parameters: \n",
    "    key: str \n",
    "    A string that determines which algorithm will be used.\n",
    "    model_params : pd.Series \n",
    "    A pandas Series holding the parameters for the algorithm.\n",
    "    data : csr_matrix\n",
    "    The trainingsdata to fit the model on. \n",
    "    ----------\n",
    "    Returns: \n",
    "    - A fitted model of the implicit library, that is initiated with and fitted on the given data. This model can be used to recommend skills to users.\n",
    "    '''\n",
    "    if key == 'als':\n",
    "        model = implicit.als.AlternatingLeastSquares(factors = model_params[\"factors\"], regularization = model_params[\"regularization\"], iterations = model_params[\"iterations\"],  random_state= 42) #,alpha= model_params[\"alpha\"]\n",
    "    elif key == 'lmf':\n",
    "        model = implicit.lmf.LogisticMatrixFactorization(factors = model_params[\"factors\"], regularization = model_params[\"regularization\"], iterations = model_params[\"iterations\"], random_state= 42)#,alpha= model_params[\"alpha\"]\n",
    "    elif key == 'bpr':\n",
    "        model = implicit.bpr.BayesianPersonalizedRanking(factors = model_params[\"factors\"], regularization = model_params[\"regularization\"], iterations = model_params[\"iterations\"], random_state= 42)\n",
    "    model.fit(data, show_progress= False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initiate_best_model(best_key, best_model, train_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the model to the baseline of most often occuring skills:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_precision_at_k(k):\n",
    "    '''\n",
    "    This function calculates the precision at k for the baseline model.\n",
    "    ----------\n",
    "    Parameters: \n",
    "    k: int \n",
    "    The number of recommended skills per user.\n",
    "    ----------\n",
    "    Returns: \n",
    "    - The precision at k for the baseline model.\n",
    "    '''\n",
    "    #########\n",
    "    # Get the most common skills\n",
    "    #########\n",
    "    most_common_skills = data_skills.sum(axis=0).nlargest(k)\t\n",
    "\n",
    "\n",
    "    #########\n",
    "    # Create a list to store the precision at k for each user\n",
    "    #########\n",
    "    p_at_5_baseline_list  = np.zeros(len(PERSONS))\n",
    "    for i in range(0,len(PERSONS)):\n",
    "        \n",
    "        #########\n",
    "        # Get all user-item-interactions for a user within the test set\n",
    "        #########\n",
    "        user_series = pd.DataFrame.sparse.from_spmatrix(test_mat, columns=data_skills.columns).loc[i]\n",
    "        \n",
    "        #########\n",
    "        # Get all user-item-interactions > 0 for a user\n",
    "        #########\n",
    "        user_known_skills = user_series[user_series > 0]\n",
    "\n",
    "        #########\n",
    "        # Check if the most common skills are in the user's known skills\n",
    "        #########\n",
    "        user_known_skills_vs_most_common = user_known_skills.index.isin(most_common_skills.index)\n",
    "\n",
    "        #########\n",
    "        # Calculate the precision at k\n",
    "        #########\n",
    "        matches = user_known_skills_vs_most_common.sum()\n",
    "        p_at_5_baseline_list[i] = matches/k\n",
    "    return p_at_5_baseline_list.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision at k = 5 of the baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.149009900990099"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_precision_at_k(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision at k = 5 of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.557907113462669"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit.evaluation.precision_at_k(model, train_user_items=train_mat, test_user_items=test_mat, K=5,show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision at k = 10 of the baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13044554455445545"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_precision_at_k(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision at k = 10 of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5253227408142999"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit.evaluation.precision_at_k(model, train_user_items=train_mat, test_user_items=test_mat, K=10,show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison between our model and the baseline:** \n",
    "\n",
    "The model predicts way more user-item-interactions, that were retained in the testdata, correct than the baseline. \n",
    "Therefore the model has to recognizes individual skill sets to a certain level. Otherwise it would not make better recommendations than the baseline. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Recommendations for a known user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictonary that holds the id of a skill as key and the name of a skill as value. <br>\n",
    "This function is necassary to exclude certain skills from the recommendations later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id and skills\n",
    "dict_skills_id = {}\n",
    "for c,skill in enumerate(data_skills.columns):\n",
    "        dict_skills_id[c] = skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_from_value(dictonary: dict, values:list):\n",
    "    '''\n",
    "    This function returns the key of a dictionary, that is associated with the given value. \n",
    "    ----------\n",
    "    Parameters: \n",
    "    dict_skills_id: dict \n",
    "    A dictionary with skills as keys and ids as values.\n",
    "    values : str \n",
    "    A string that is associated with a key in the dictionary.\n",
    "    ----------\n",
    "    Returns: \n",
    "    - A list holding the keys to the corresponding values.\n",
    "    '''\n",
    "    output = [k for k,v in dictonary.items() for val in values if v == val]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations (model,userids:list, mat:csr_matrix ,eval_mat:csr_matrix = None ,items_to_exclude:list = None ,n:int = 5):\n",
    "    '''\n",
    "    This function produces recommendations for known user. \n",
    "    ----------\n",
    "    Parameters: \n",
    "    model :\n",
    "    A trained model from the implicit library.\n",
    "    userids : list\n",
    "    A list that holds the userids for which recommendations will be generated. \n",
    "    train_mat : csr_matrix\n",
    "    A user-item matrix that holds the known items for the given users.\n",
    "    test_mat : csr_matrix\n",
    "    Optional: A user-item matrix that holds user-item interactions and can be used for evaluation.\n",
    "    items_to_exclude : list\n",
    "    Optional: A list that holds the items that should be excluded from the recommendations.\n",
    "    n : int\n",
    "    Optional: The number of recommendations that will be generated\n",
    "    .\n",
    "    ----------\n",
    "    Returns: \n",
    "    - A pandas DataFrame that holds the recommendations for the given users.\n",
    "    '''\n",
    "    output = pd.DataFrame()\n",
    "    if items_to_exclude is not None:\n",
    "        items_to_exclude  = get_key_from_value(dict_skills_id,items_to_exclude)\n",
    "\n",
    "    for u in userids:\n",
    "        \n",
    "        \n",
    "        #############\n",
    "        # Do recommendations for every user in the list. The known items are in the matrix the model was trained on\n",
    "        #############\n",
    "\n",
    "        skill_ids, scores  = model.recommend(u, user_items= mat[u], N = n , filter_already_liked_items=True, filter_items = items_to_exclude)\n",
    "        recommendations_df = pd.DataFrame({\"skill\": [dict_skills_id[skill] for skill in skill_ids], \"score\": scores})\n",
    "\n",
    "        #############\n",
    "        # Get all known skills for each user by indexing the full data matrix\n",
    "        #############\n",
    "        \n",
    "        if eval_mat is not None:\n",
    "            eval_data = pd.DataFrame.sparse.from_spmatrix(data = eval_mat.tocsr()[u],columns=data_skills.columns).T.reset_index().rename(columns = {\"index\": \"skill\",0: \"rating\"}).sort_values(by = \"rating\", ascending = False)\n",
    "   \n",
    "            #############\n",
    "            # Merge both df in order to see, if the recommended skills are the skills, which the user already knows, but were left out in the trainings data\n",
    "            #############\n",
    "            recommendations_df = recommendations_df.merge(eval_data, on = [\"skill\"], how = \"left\").rename(columns = {\"rating\": \"rating_in_test_data\"})\n",
    "\n",
    "\n",
    "        #############\n",
    "        # Merge the category information to the recommendations\n",
    "        #############\n",
    "        recommendations_df = recommendations_df.merge(data_categories, on = \"skill\", how = \"left\")\n",
    "        recommendations_df[\"user_id\"]  = u\n",
    "        recommendations_df = recommendations_df.set_index(\"user_id\")\n",
    "        output = pd.concat([output, recommendations_df])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>score</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REST</td>\n",
       "      <td>0.895471</td>\n",
       "      <td>Standards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unit Tests (Komponententests)</td>\n",
       "      <td>0.799572</td>\n",
       "      <td>Methoden und Praktiken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MySQL</td>\n",
       "      <td>0.771677</td>\n",
       "      <td>Datenbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Windows 7</td>\n",
       "      <td>0.693613</td>\n",
       "      <td>Betriebssystem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dependency Injection</td>\n",
       "      <td>0.616234</td>\n",
       "      <td>Methoden und Praktiken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Implementierung</td>\n",
       "      <td>0.834961</td>\n",
       "      <td>Einsatzfelder / Erfahrungen / Schwerpunkte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MySQL</td>\n",
       "      <td>0.739386</td>\n",
       "      <td>Datenbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test Driven Development (TDD)</td>\n",
       "      <td>0.708436</td>\n",
       "      <td>Methoden und Praktiken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Visual Studio</td>\n",
       "      <td>0.676905</td>\n",
       "      <td>Umgebungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LINQ</td>\n",
       "      <td>0.662311</td>\n",
       "      <td>.NET Frameworks und Tools</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 skill     score  \\\n",
       "user_id                                            \n",
       "0                                 REST  0.895471   \n",
       "0        Unit Tests (Komponententests)  0.799572   \n",
       "0                                MySQL  0.771677   \n",
       "0                            Windows 7  0.693613   \n",
       "0                 Dependency Injection  0.616234   \n",
       "1                      Implementierung  0.834961   \n",
       "1                                MySQL  0.739386   \n",
       "1        Test Driven Development (TDD)  0.708436   \n",
       "1                        Visual Studio  0.676905   \n",
       "1                                 LINQ  0.662311   \n",
       "\n",
       "                                           category  \n",
       "user_id                                              \n",
       "0                                         Standards  \n",
       "0                            Methoden und Praktiken  \n",
       "0                                         Datenbank  \n",
       "0                                    Betriebssystem  \n",
       "0                            Methoden und Praktiken  \n",
       "1        Einsatzfelder / Erfahrungen / Schwerpunkte  \n",
       "1                                         Datenbank  \n",
       "1                            Methoden und Praktiken  \n",
       "1                                        Umgebungen  \n",
       "1                         .NET Frameworks und Tools  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userid= [0,1]\n",
    "get_recommendations(model, userid, train_mat, items_to_exclude = [\"SCRUM\"], n = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recommendations for a new user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate a new user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id = 404\n",
    "new_skills = {\n",
    "                \"Englisch\":1,\n",
    "                 \"Chinesisch (Mandarin)\":1,\n",
    "                \"Python\":1,\n",
    "                 \"MATLAB\":1,\n",
    "                \"Java\":1,\n",
    "                \"MySQL\":1,\n",
    "                \"SQLBase\":1,\n",
    "                \"Microsoft SQL Server\":1,\n",
    "                \"Google Cloud Platform\":1,\n",
    "                \"MongoDB\":1,\n",
    "                \"JSON\":1,\n",
    "                \"Docker\":1,\n",
    "                \"Power BI\":1,\n",
    "                \"Postman\":1,\n",
    "                \"PowerShell\":1,\n",
    "                \"Github actions\":1\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_new_user(model, userid:int, user_skills:dict, old_user_mat:csr_matrix, items_to_exclude:list = None ,n:int = 5):\n",
    "    '''\n",
    "    This function produces recommendations for a new user. \n",
    "    ----------\n",
    "    Parameters: \n",
    "    model :\n",
    "    A trained model from the implicit library.\n",
    "    userid : int\n",
    "    The id of the new user. \n",
    "    user_skills : dict\n",
    "    A dictonary contain.\n",
    "    old_user_mat : csr_matrix\n",
    "    Optional: A user-item matrix on which the model was trained on.\n",
    "    items_to_exclude : list\n",
    "    Optional: A list that holds the items that should be excluded from the recommendations.\n",
    "    n : int\n",
    "    Optional: The number of recommendations that will be generated\n",
    "    .\n",
    "    ----------\n",
    "    Returns: \n",
    "    - A pandas DataFrame that holds the recommendations for a new users.\n",
    "    '''\n",
    "\n",
    "    #############\n",
    "    # Create a new user as dataframe, where a row represents a user and the columns represent the skills of that user\n",
    "    #############\n",
    "    new_user = pd.DataFrame(user_skills, index = [userid])\n",
    "\n",
    "\n",
    "    #############\n",
    "    # Append the new user to the old user matrix and fill the missing values with 0\n",
    "    #############\n",
    "    mat = pd.concat([old_user_mat,new_user]).sort_index().fillna(0).astype(int)\n",
    "    mat = scipy.sparse.csr_matrix(mat.values)\n",
    "\n",
    "    #############\n",
    "    # Transform the matrix which contains the new user according to the results of the grid search\n",
    "    #############\n",
    "    best_grid_bm25  = { 'X': mat, 'K1': best_model[\"K1\"], 'B': best_model[\"B\"] }\n",
    "    \n",
    "    data_representation_dict  = {\n",
    "                                'Raw':mat\n",
    "                                ,'Normalized':  implicit.nearest_neighbours.normalize(mat)\n",
    "                                ,'tfidf':implicit.nearest_neighbours.tfidf_weight(mat)\n",
    "                                ,'bm25':implicit.nearest_neighbours.bm25_weight(**best_grid_bm25)\n",
    "                                }   \n",
    " \n",
    "    mat = data_representation_dict[best_model[\"data_representations\"]]\n",
    "    mat = mat.tocsr()\n",
    "\n",
    "    #############\n",
    "    # Do recommendations for the new user\n",
    "    #############\n",
    "\n",
    "    skill_ids, scores  = model.recommend(userid, user_items= mat[userid], N = n , filter_already_liked_items=True, filter_items = items_to_exclude, recalculate_user=True)\n",
    "    recommendations_df = pd.DataFrame({\"skill\": [dict_skills_id[skill] for skill in skill_ids], \"score\": scores})\n",
    "\n",
    "    #############\n",
    "    # Merge the category information to the recommendations\n",
    "    #############\n",
    "    recommendations_df = recommendations_df.merge(data_categories, on = \"skill\", how = \"left\")\n",
    "    recommendations_df[\"user_id\"]  = userid\n",
    "    recommendations_df = recommendations_df.set_index(\"user_id\")\n",
    " \n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>score</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>GIT</td>\n",
       "      <td>0.203037</td>\n",
       "      <td>CI/CD, Build- und Versionskontrollsysteme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>SQL</td>\n",
       "      <td>0.195899</td>\n",
       "      <td>Datenbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>0.190778</td>\n",
       "      <td>Programmiersprachen / Scriptsprachen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>SCRUM</td>\n",
       "      <td>0.175187</td>\n",
       "      <td>Projektmanagement / Vorgehensmodelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>REST</td>\n",
       "      <td>0.172791</td>\n",
       "      <td>Standards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill     score                                   category\n",
       "user_id                                                                 \n",
       "404             GIT  0.203037  CI/CD, Build- und Versionskontrollsysteme\n",
       "404             SQL  0.195899                                  Datenbank\n",
       "404      JavaScript  0.190778       Programmiersprachen / Scriptsprachen\n",
       "404           SCRUM  0.175187       Projektmanagement / Vorgehensmodelle\n",
       "404            REST  0.172791                                  Standards"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations_new_user(model,new_id, new_skills, data_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix I - Effect of Dropping Rare Skills on Recommender Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By dropping skills we can investigate the tradeoff between a matrix with a higher level of density and the removal of distinguishing features.\n",
    "\n",
    "Rare skills serve as distinguishing feature for users, because they will have assigned a value after tf-idf or bm25 transformation. \n",
    "\n",
    "***for more details about tf-idf and bm25 please have a look at our documentation***  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***HIER MUSS ICH NOCH MEIN GRID DURCHLAUFEN LASSEN DAMIT ICH MEINE BESTEN PARAMETER WEI=***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infos best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    40\n",
       "data_representations         Raw\n",
       "K1                           NaN\n",
       "B                            NaN\n",
       "factors                        9\n",
       "regularization              0.01\n",
       "iterations                    15\n",
       "alpha                          1\n",
       "precision_at_k          0.571333\n",
       "map_at_k                0.462859\n",
       "ndcg_at_k                0.56003\n",
       "Name: 40, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance_for_n(min_support:list):\n",
    "    '''\n",
    "    This function measures the performance of a recommender system across matrices with a different level of sparsity. \n",
    "    ----------\n",
    "    Parameters: \n",
    "    min_support : list\n",
    "    A list of integers that represent the minimum absolute support threshold. Items/ skills with a lower absolute support will be removed from the dataset.\n",
    "    ----------\n",
    "    Returns: \n",
    "    - A pandas DataFrame that demonstrates the effect of the sparsity on the performance of the recommender system (c.p.).\n",
    "    '''\n",
    "    output = pd.DataFrame()\n",
    "    for n in min_support:\n",
    "        #############\n",
    "        # Import the data\n",
    "        #############\n",
    "        df = pd.read_csv(\"data/person-skills_2022-06-27.csv\",sep=\";\") \n",
    "\n",
    "        #############\n",
    "        # trim dataset according to min absolute support of skills and insert ratings afterwards\n",
    "        #############\n",
    "        rare_skills = get_rare_skills(df,n)\n",
    "        df = df[~df[\"skill\"].isin(rare_skills)]\n",
    "        unique_skills = df[\"skill\"].nunique()\n",
    "\n",
    "        #############\n",
    "        # Create a user-item matrix\n",
    "        #############\n",
    "        df[\"count\"] = 1\n",
    "        matrix = df.pivot_table('count', index='person', columns=\"skill\").fillna(0).astype(int).reset_index(drop=True)\n",
    "        matrix.index.names = [\"userids\"]\n",
    "        matrix_csr = scipy.sparse.csr_matrix(matrix.values)\n",
    "        \n",
    "        #############\n",
    "        # Measure sparsity (ratio between non-zero and zero value entries) of the trainset\n",
    "        #############\n",
    "        number_of_elements_in_matrix = matrix_csr.shape[0] * matrix_csr.shape[1]\n",
    "        number_of_nonzeros_in_matrix = matrix_csr.sum()\n",
    "\n",
    "        sparsity = 1 - number_of_nonzeros_in_matrix/number_of_elements_in_matrix\n",
    "        sparsity = round(sparsity,4)\n",
    "        #############\n",
    "        # Split the data into train and test set\n",
    "        #############\n",
    "        train_mat, test_mat = implicit.evaluation.train_test_split(matrix_csr, train_percentage =  0.8, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "        #############\n",
    "        # Initialize the model\n",
    "        #############\n",
    "        model = initiate_best_model(best_key, best_model, train_mat)\n",
    "\n",
    "        \n",
    "        prec_at_k = precision_at_k(model, train_mat, test_mat, K = 5, show_progress = False)\n",
    "        map_at_k = mean_average_precision_at_k(model, train_mat, test_mat, K = 5, show_progress = False)\n",
    "        var_ndcg_at_k = ndcg_at_k(model, train_mat, test_mat, K = 5, show_progress = False)\n",
    "        result = pd.DataFrame({\n",
    "                                \"unique_skills\":unique_skills\n",
    "                                ,\"sparsity\": sparsity\n",
    "                                ,\"precision_at_k\": prec_at_k\n",
    "                                ,\"map_at_k\": map_at_k\n",
    "                                ,\"ndcg_at_k\": var_ndcg_at_k\n",
    "                                }, index = [n])\n",
    "\n",
    "        result.index.names = [\"min_support\"] \n",
    "        output = pd.concat([output,result])\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum absolute support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_absolute_support = [0, 1, 2, 5, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_skills</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>map_at_k</th>\n",
       "      <th>ndcg_at_k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_support</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.557907</td>\n",
       "      <td>0.447865</td>\n",
       "      <td>0.542808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>665</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.600120</td>\n",
       "      <td>0.489343</td>\n",
       "      <td>0.581912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>614</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.576651</td>\n",
       "      <td>0.471844</td>\n",
       "      <td>0.567836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>510</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.455219</td>\n",
       "      <td>0.554607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>392</td>\n",
       "      <td>0.8558</td>\n",
       "      <td>0.574808</td>\n",
       "      <td>0.465579</td>\n",
       "      <td>0.564256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>270</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>0.603214</td>\n",
       "      <td>0.484912</td>\n",
       "      <td>0.579966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             unique_skills  sparsity  precision_at_k  map_at_k  ndcg_at_k\n",
       "min_support                                                              \n",
       "0                      734    0.9185        0.557907  0.447865   0.542808\n",
       "1                      665    0.9101        0.600120  0.489343   0.581912\n",
       "2                      614    0.9028        0.576651  0.471844   0.567836\n",
       "5                      510    0.8849        0.565657  0.455219   0.554607\n",
       "10                     392    0.8558        0.574808  0.465579   0.564256\n",
       "20                     270    0.8052        0.603214  0.484912   0.579966"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_performance_for_n(min_absolute_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion regarding the effect of dropping rare skills:** <br>\n",
    "We can observe, that lowering the sparsity of a matrix does not necessarily lead to a higher precision at k score. \n",
    "Nevertheless it can still increase the precision at k slightly, but the tradeoff is not worth it, because a majority of all available skills will not be part of the models recommendations anymore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix II -  Reverse Problem for User Recommendations on Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose the user-item-matrix in order to get a item-user matrix and use the transformation technique on it, that achieved the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<734x404 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 24156 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_best_u = implicit.nearest_neighbours.bm25_weight(data_skills_csr.T, K1 = 100, B = 0.8)\n",
    "data_best_u = data_best_u.tocsr()\n",
    "data_best_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train-test-split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat_u, test_mat_u = implicit.evaluation.train_test_split(data_best_u, train_percentage =  0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model_best_u = implicit.als.AlternatingLeastSquares(factors = 30, regularization = 0.01, iterations = 15,random_state = 42)# alpha = 1, \n",
    "model_best_u.fit(train_mat_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_reversed (model,skillids:list, mat:csr_matrix ,eval_mat:csr_matrix = None ,items_to_exclude:list = None ,n:int = 5):\n",
    "    '''\n",
    "    This function recommends,which users are most likely qualified to learn a certain skill. \n",
    "    ----------\n",
    "    Parameters: \n",
    "    model :\n",
    "    A trained model from the implicit library.\n",
    "    skillids : list\n",
    "    A list that holds the skill ids for which recommendations will be generated. \n",
    "    mat : csr_matrix\n",
    "    A item-user matrix that holds the known users for the given skill.\n",
    "    eval_mat : csr_matrix\n",
    "    Optional: A item-user matrix that holds item-user interactions and can be used for evaluation.\n",
    "    items_to_exclude : list\n",
    "    Optional: A list that holds the users, who should be excluded from the recommendations.\n",
    "    n : int\n",
    "    Optional: The number of recommendations that will be generated\n",
    "    .\n",
    "    ----------\n",
    "    Returns: \n",
    "    - A pandas DataFrame that holds the recommendations for the given skill.\n",
    "    '''\n",
    "    output = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    #skillids  = get_key_from_value(dict_skills_id,skillids)\n",
    "    #skillids = [s[0] for s in skillids]\n",
    "    for value in skillids:\n",
    "        key  = get_key_from_value(dict_skills_id,[value])\n",
    "        key = key[0]\n",
    "        #############\n",
    "        # Do recommendations for every user in the list. The known items are in the matrix the model was trained on\n",
    "        #############\n",
    "\n",
    "        user_ids, scores  = model.recommend(key, user_items= mat[key], N = n , filter_already_liked_items=True, filter_items = items_to_exclude)\n",
    "        recommendations_df = pd.DataFrame({\"user_id\": user_ids, \"score\": scores})\n",
    "\n",
    "        #############\n",
    "        # Get all known skills for each user by indexing the full data matrix\n",
    "        #############\n",
    "        \n",
    "        if eval_mat is not None:\n",
    "            eval_data = pd.DataFrame.sparse.from_spmatrix(data = eval_mat.tocsr()[s],columns=data_skills.columns).T.reset_index().rename(columns = {\"index\": \"user_id\",0: \"rating\"}).sort_values(by = \"rating\", ascending = False)\n",
    "   \n",
    "            #############\n",
    "            # Merge both df in order to see, if the recommended skills are the skills, which the user already knows, but were left out in the trainings data\n",
    "            #############\n",
    "            recommendations_df = recommendations_df.merge(eval_data, on = [\"user_id\"], how = \"left\").rename(columns = {\"rating\": \"rating_in_test_data\"})\n",
    "\n",
    "\n",
    "\n",
    "        recommendations_df[\"skill_id\"]  = value\n",
    "        recommendations_df = recommendations_df.set_index(\"skill_id\")\n",
    "        output = pd.concat([output, recommendations_df])\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>270</td>\n",
       "      <td>0.713534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>12</td>\n",
       "      <td>0.673033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>309</td>\n",
       "      <td>0.659310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>392</td>\n",
       "      <td>0.614753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>47</td>\n",
       "      <td>0.506845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>239</td>\n",
       "      <td>0.869117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>316</td>\n",
       "      <td>0.688858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>241</td>\n",
       "      <td>0.676700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>353</td>\n",
       "      <td>0.638023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>213</td>\n",
       "      <td>0.620544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     score\n",
       "skill_id                   \n",
       "Python        270  0.713534\n",
       "Python         12  0.673033\n",
       "Python        309  0.659310\n",
       "Python        392  0.614753\n",
       "Python         47  0.506845\n",
       "Java          239  0.869117\n",
       "Java          316  0.688858\n",
       "Java          241  0.676700\n",
       "Java          353  0.638023\n",
       "Java          213  0.620544"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations_reversed(model_best_u, [\"Python\",\"Java\"],train_mat_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix III - Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simularities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_key_from_value(dict_skills_id,[\".NET Framework\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '.NET Compact Framework',\n",
       " 1: '.NET Core',\n",
       " 2: '.NET Framework',\n",
       " 3: '3D-Modellierung',\n",
       " 4: 'ABAP',\n",
       " 5: 'ADO.NET',\n",
       " 6: 'AIX',\n",
       " 7: 'ARIS',\n",
       " 8: 'ARIS ITArchitect',\n",
       " 9: 'AS400',\n",
       " 10: 'ASP Generalist',\n",
       " 11: 'ASP.NET',\n",
       " 12: 'ASP.NET MVC-Framework',\n",
       " 13: 'ASP.NET WebAPI',\n",
       " 14: 'AWS',\n",
       " 15: 'AWS Lambda',\n",
       " 16: 'Abstract',\n",
       " 17: 'Access',\n",
       " 18: 'Accessibility / WCAG',\n",
       " 19: 'Active Directory',\n",
       " 20: 'ActiveX',\n",
       " 21: 'Adobe CC',\n",
       " 22: 'Adobe Flash',\n",
       " 23: 'Adobe Illustrator',\n",
       " 24: 'Adobe InDesign',\n",
       " 25: 'Adobe Photoshop',\n",
       " 26: 'Adobe Premiere',\n",
       " 27: 'Adobe XD',\n",
       " 28: 'After Effects',\n",
       " 29: 'Agile Methoden',\n",
       " 30: 'Ajax',\n",
       " 31: 'Alexa-Skills',\n",
       " 32: 'Alpine',\n",
       " 33: 'Analytics',\n",
       " 34: 'Android',\n",
       " 35: 'Android Studio',\n",
       " 36: 'Anforderungsanalyse',\n",
       " 37: 'Anforderungsmanagement',\n",
       " 38: 'Angular (2 und höher)',\n",
       " 39: 'Angular Generalist',\n",
       " 40: 'Angular Material',\n",
       " 41: 'Angular Theming',\n",
       " 42: 'AngularJS',\n",
       " 43: 'Animations (transition, @keyframes)',\n",
       " 44: 'Ansible',\n",
       " 45: 'Ant',\n",
       " 46: 'Apache',\n",
       " 47: 'Apache Derby',\n",
       " 48: 'Apache JMeter',\n",
       " 49: 'App UX',\n",
       " 50: 'AppCode',\n",
       " 51: 'Apple Mac OS X Server',\n",
       " 52: 'Aptana',\n",
       " 53: 'Arabisch',\n",
       " 54: 'Arch Linux',\n",
       " 55: 'Arduino C',\n",
       " 56: 'Aspektorientierte Programmierung (AOP)',\n",
       " 57: 'Assembler',\n",
       " 58: 'Atomic Design',\n",
       " 59: 'Augmented Reality',\n",
       " 60: 'Autocad',\n",
       " 61: 'Automotive',\n",
       " 62: 'Axure RP',\n",
       " 63: 'Azure',\n",
       " 64: 'Azure DevOps',\n",
       " 65: 'B2B',\n",
       " 66: 'B2B Accelerator Experience',\n",
       " 67: 'B2B Commerce',\n",
       " 68: 'B2C',\n",
       " 69: 'B2C Accelerator Experience',\n",
       " 70: 'B2C Commerce',\n",
       " 71: 'BEM - Block Element Modifier',\n",
       " 72: 'BEMIT (BEM + ITCSS)',\n",
       " 73: 'BPMN',\n",
       " 74: 'BSD',\n",
       " 75: 'BaaN/Infor ERP LN',\n",
       " 76: 'Backoffice Konfiguration',\n",
       " 77: 'BashScript',\n",
       " 78: 'Behaviour Driven Development (BDD)',\n",
       " 79: 'Bitbucket',\n",
       " 80: 'BizAgi Process Modeler',\n",
       " 81: 'BizTalk',\n",
       " 82: 'BlackBerry OS',\n",
       " 83: 'Blazor .Net',\n",
       " 84: 'Blender',\n",
       " 85: 'Bootstrap',\n",
       " 86: 'Browser Debugging',\n",
       " 87: 'Browser Technologien',\n",
       " 88: 'Bugzilla',\n",
       " 89: 'Business Consulting',\n",
       " 90: 'BusinessObjects',\n",
       " 91: 'C#',\n",
       " 92: 'C/C++',\n",
       " 93: 'CBuilder',\n",
       " 94: 'CI/CD Entwicklung',\n",
       " 95: 'CISCO Switch Administration',\n",
       " 96: 'CMake',\n",
       " 97: 'CORBA',\n",
       " 98: 'CSM – Scrum Master',\n",
       " 99: 'CSPO – Product Owner',\n",
       " 100: 'CSS',\n",
       " 101: 'CVS',\n",
       " 102: 'Caddy',\n",
       " 103: 'CakePHP',\n",
       " 104: 'CalDAV',\n",
       " 105: 'Canvas',\n",
       " 106: 'Castor',\n",
       " 107: 'Chinesisch (Mandarin)',\n",
       " 108: 'Citrix',\n",
       " 109: 'Clean Code',\n",
       " 110: 'Clear Case',\n",
       " 111: 'Cloud Computing Generalist',\n",
       " 112: 'Cobol',\n",
       " 113: 'Cocoon',\n",
       " 114: 'Code Reviews',\n",
       " 115: 'CodeIgniter',\n",
       " 116: 'Cognos',\n",
       " 117: 'ColdFusion MX',\n",
       " 118: 'ComExpress',\n",
       " 119: 'Command and Query Responsibility Segregation',\n",
       " 120: 'Concourse',\n",
       " 121: 'Confluence',\n",
       " 122: 'Contao',\n",
       " 123: 'Content Delivery Network Anbindung - ( CDN )',\n",
       " 124: 'Content Marketing',\n",
       " 125: 'Content-Platform',\n",
       " 126: 'Continuous Integration (CI)',\n",
       " 127: 'Conversion Optimierung',\n",
       " 128: 'CoreShop',\n",
       " 129: 'Corel Draw',\n",
       " 130: 'CouchDB',\n",
       " 131: 'Cruise Control.NET',\n",
       " 132: 'CruiseControl',\n",
       " 133: 'Crystal Reports',\n",
       " 134: 'Cucumber',\n",
       " 135: 'Cypress',\n",
       " 136: 'DB2 / UDB',\n",
       " 137: 'DBase/Clipper',\n",
       " 138: 'DEV Ops Experience',\n",
       " 139: 'DHCP',\n",
       " 140: 'DNS',\n",
       " 141: 'Dart',\n",
       " 142: 'Datadog',\n",
       " 143: 'Datahub Anbindung',\n",
       " 144: 'Datenaufbereitung & Datenanalyse',\n",
       " 145: 'Datenschutzauditor',\n",
       " 146: 'Datenschutzbeauftragter',\n",
       " 147: 'Debian',\n",
       " 148: 'Delphi',\n",
       " 149: 'Dependency Injection',\n",
       " 150: 'Design Driven Development (DDD)',\n",
       " 151: 'Design Pattern',\n",
       " 152: 'Design Reviews',\n",
       " 153: 'Design Sprints',\n",
       " 154: 'Design Systeme',\n",
       " 155: 'Design Systems',\n",
       " 156: 'Design Thinking',\n",
       " 157: 'Deutsch',\n",
       " 158: 'DevExpress',\n",
       " 159: 'Dienstleistungen',\n",
       " 160: 'Digital Research',\n",
       " 161: 'Digitale Barrierefreiheit',\n",
       " 162: 'DirectX',\n",
       " 163: 'Django',\n",
       " 164: 'Docker',\n",
       " 165: 'Dojo',\n",
       " 166: 'Dojo Toolkit',\n",
       " 167: 'Dokumentation',\n",
       " 168: 'Domain Driven Design',\n",
       " 169: 'Dreamweaver',\n",
       " 170: 'Drupal',\n",
       " 171: 'DynDNS',\n",
       " 172: 'Dynamics 365',\n",
       " 173: 'Dynamics NAV/Navision',\n",
       " 174: 'Dänisch',\n",
       " 175: 'E-Commerce',\n",
       " 176: 'EFS Survey',\n",
       " 177: 'EJB 3',\n",
       " 178: 'Eclipse',\n",
       " 179: 'Eclipse Smarthome (ESH)',\n",
       " 180: 'Elasticsearch',\n",
       " 181: 'Electron',\n",
       " 182: 'Emarsys Anbindung',\n",
       " 183: 'Englisch',\n",
       " 184: 'Enterprise Architect',\n",
       " 185: 'Entity Framework',\n",
       " 186: 'Entity Framework Core',\n",
       " 187: 'Entwurfsmuster',\n",
       " 188: 'EventModeling',\n",
       " 189: 'Exact',\n",
       " 190: 'Express.js',\n",
       " 191: 'ExtBase',\n",
       " 192: 'ExtJs',\n",
       " 193: 'Extensions',\n",
       " 194: 'F#',\n",
       " 195: 'FMCG',\n",
       " 196: 'FibuNet',\n",
       " 197: 'Figma',\n",
       " 198: 'FileZilla',\n",
       " 199: 'Final Cut',\n",
       " 200: 'Finance',\n",
       " 201: 'Finnisch',\n",
       " 202: 'Firebase',\n",
       " 203: 'Firewall (IP Tables)',\n",
       " 204: 'Fireworks',\n",
       " 205: 'First Spirit',\n",
       " 206: 'Fluid Templates',\n",
       " 207: 'Flutter',\n",
       " 208: 'Fortran',\n",
       " 209: 'Foundation - responsive Frontend-Framework',\n",
       " 210: 'Fractal',\n",
       " 211: 'Französisch',\n",
       " 212: 'FreeBSD',\n",
       " 213: 'Frontify',\n",
       " 214: 'GEF',\n",
       " 215: 'GIMP',\n",
       " 216: 'GIT',\n",
       " 217: 'Gewaltfreie Kommunikation',\n",
       " 218: 'Gherkin',\n",
       " 219: 'GitHub',\n",
       " 220: 'Github actions',\n",
       " 221: 'Gitlab',\n",
       " 222: 'Gitlab CI',\n",
       " 223: 'Glasfish',\n",
       " 224: 'Go',\n",
       " 225: 'Google Analytics',\n",
       " 226: 'Google Android',\n",
       " 227: 'Google Cloud Platform',\n",
       " 228: 'Google Tag Manager',\n",
       " 229: 'Google Test / Google Mock',\n",
       " 230: 'Google Web Toolkit',\n",
       " 231: 'Governikus',\n",
       " 232: 'Grafana',\n",
       " 233: 'Grafik Design',\n",
       " 234: 'GraphQL',\n",
       " 235: 'Griechisch',\n",
       " 236: 'Groovy',\n",
       " 237: 'Grunt',\n",
       " 238: 'Gulp',\n",
       " 239: 'HP/UX',\n",
       " 240: 'HPQC',\n",
       " 241: 'HTML',\n",
       " 242: 'HTML5',\n",
       " 243: 'Handel',\n",
       " 244: 'Handlebars',\n",
       " 245: 'Hardware',\n",
       " 246: 'HarePoint',\n",
       " 247: 'Haskell',\n",
       " 248: 'Heroku',\n",
       " 249: 'Hibernate',\n",
       " 250: 'Homesite',\n",
       " 251: 'Hybris',\n",
       " 252: 'IBM Infosphere DataStage',\n",
       " 253: 'IBM WebSphere',\n",
       " 254: 'IRQuest',\n",
       " 255: 'ISTQB - Foundation Level',\n",
       " 256: 'IT Consulting',\n",
       " 257: 'ITCSS',\n",
       " 258: 'ITIL',\n",
       " 259: 'Iconography ',\n",
       " 260: 'Implementierung',\n",
       " 261: 'Infinispan',\n",
       " 262: 'InfluxDB',\n",
       " 263: 'Informatica',\n",
       " 264: 'Informix',\n",
       " 265: 'Infragistics',\n",
       " 266: 'InstallShield',\n",
       " 267: 'IntelliJ(Idea)',\n",
       " 268: 'Interbase/Firebird',\n",
       " 269: 'Internet Information Services (IIS)',\n",
       " 270: 'Invision',\n",
       " 271: 'Ionic',\n",
       " 272: 'Italienisch',\n",
       " 273: 'JBoss',\n",
       " 274: 'JBuilder',\n",
       " 275: 'JDBC',\n",
       " 276: 'JDeveloper',\n",
       " 277: 'JIRA',\n",
       " 278: 'JRun',\n",
       " 279: 'JSF',\n",
       " 280: 'JSON',\n",
       " 281: 'JSP',\n",
       " 282: 'JUnit',\n",
       " 283: 'Jakarta Commons',\n",
       " 284: 'Jakarta EE',\n",
       " 285: 'Jama',\n",
       " 286: 'Jasmine',\n",
       " 287: 'Java',\n",
       " 288: 'Java EE',\n",
       " 289: 'Java FX',\n",
       " 290: 'Java ME',\n",
       " 291: 'Java Native Interface (JNI)',\n",
       " 292: 'JavaScript',\n",
       " 293: 'Jenkins',\n",
       " 294: 'Jest',\n",
       " 295: 'Jogl',\n",
       " 296: 'Joomla',\n",
       " 297: 'Juristische Ausbildung',\n",
       " 298: 'KANBAN',\n",
       " 299: 'Karaf',\n",
       " 300: 'Kendo UI',\n",
       " 301: 'Keycloak',\n",
       " 302: 'Konzeption',\n",
       " 303: 'Kotlin',\n",
       " 304: 'Kubernetes',\n",
       " 305: 'Kunst, Kultur & Events',\n",
       " 306: 'LDAP',\n",
       " 307: 'LINQ',\n",
       " 308: 'LaTeX',\n",
       " 309: 'Laravel',\n",
       " 310: 'Layouting (Flexbox, CSS Grid)',\n",
       " 311: 'Lead Generierung',\n",
       " 312: 'Less',\n",
       " 313: 'Linux Printserver',\n",
       " 314: 'Liquibase',\n",
       " 315: 'Log4J',\n",
       " 316: 'Logistik',\n",
       " 317: 'MAC OS 7/8/9',\n",
       " 318: 'MAC OS X',\n",
       " 319: 'MATLAB',\n",
       " 320: 'MFC/Windows-API',\n",
       " 321: 'MQSeries',\n",
       " 322: 'MS Exchange',\n",
       " 323: 'MS Project',\n",
       " 324: 'MSBuild',\n",
       " 325: 'MVS',\n",
       " 326: 'Magento',\n",
       " 327: 'Management Consulting',\n",
       " 328: 'Mantis',\n",
       " 329: 'MariaDB',\n",
       " 330: 'Markdown ',\n",
       " 331: 'Marken',\n",
       " 332: 'Markenstrategie',\n",
       " 333: 'Maven',\n",
       " 334: 'MaxDB',\n",
       " 335: 'Medien- und Kommunikationsforschung',\n",
       " 336: 'Mediengestalter Digital & Print - Fachrichtung Gestaltung & Technik',\n",
       " 337: 'Medizintechnik',\n",
       " 338: 'Mercurial',\n",
       " 339: 'Microservices',\n",
       " 340: 'Microsoft Access',\n",
       " 341: 'Microsoft Enterprise Library',\n",
       " 342: 'Microsoft Office',\n",
       " 343: 'Microsoft SQL Server',\n",
       " 344: 'Microsoft Teams',\n",
       " 345: 'Microsoft Visio',\n",
       " 346: 'Miro',\n",
       " 347: 'Mobile UX',\n",
       " 348: 'Mocha',\n",
       " 349: 'Mockito',\n",
       " 350: 'Moderation',\n",
       " 351: 'Modularer Designaufbau',\n",
       " 352: 'MongoDB',\n",
       " 353: 'Mono',\n",
       " 354: 'MonoDevelop',\n",
       " 355: 'MooTools',\n",
       " 356: 'Mozilla FW',\n",
       " 357: 'Multiplattform/Multibrowser Testing',\n",
       " 358: 'Mural',\n",
       " 359: 'Mustache',\n",
       " 360: 'MySQL',\n",
       " 361: 'NEOS',\n",
       " 362: 'NFS',\n",
       " 363: 'NGRX',\n",
       " 364: 'NHibernate',\n",
       " 365: 'NUnit',\n",
       " 366: 'NativeScript',\n",
       " 367: 'NestJS',\n",
       " 368: 'NetBeans',\n",
       " 369: 'Netlify CMS',\n",
       " 370: 'Netviewer',\n",
       " 371: 'Newsletter Anbindung',\n",
       " 372: 'Niederländisch',\n",
       " 373: 'NoSQL',\n",
       " 374: 'Node.js',\n",
       " 375: 'Novell',\n",
       " 376: 'Nuxt',\n",
       " 377: 'OAuth',\n",
       " 378: 'OS/2',\n",
       " 379: 'OSGi',\n",
       " 380: 'OXID eShop',\n",
       " 381: 'Objective-C',\n",
       " 382: 'Objektrelationale Abbildung (ORM)',\n",
       " 383: 'Odata',\n",
       " 384: 'Office365',\n",
       " 385: 'Omni Commerce Connect (OCC) Rest APIs',\n",
       " 386: 'Online Marketing',\n",
       " 387: 'Open Broadcaster Software (OBS)',\n",
       " 388: 'Open SSH',\n",
       " 389: 'OpenAPI',\n",
       " 390: 'OpenBSD',\n",
       " 391: 'OpenExchange',\n",
       " 392: 'OpenGL',\n",
       " 393: 'OpenHAB',\n",
       " 394: 'OpenOffice / LibreOffice',\n",
       " 395: 'OpenShop',\n",
       " 396: 'Oracle',\n",
       " 397: 'Oracle AS',\n",
       " 398: 'Oracle Applications',\n",
       " 399: 'Oracle Forms',\n",
       " 400: 'Oracle Warehouse',\n",
       " 401: 'Oracle XDK',\n",
       " 402: 'Orga',\n",
       " 403: 'PCI-DSS ',\n",
       " 404: 'PEAR',\n",
       " 405: 'PHP',\n",
       " 406: 'PHP/Horde',\n",
       " 407: 'PHPStan',\n",
       " 408: 'PHPUnit',\n",
       " 409: 'PL/SQL',\n",
       " 410: 'PMI',\n",
       " 411: 'PRINCE2',\n",
       " 412: 'PVCS',\n",
       " 413: 'PWA',\n",
       " 414: 'PaintShop',\n",
       " 415: 'PalmOS',\n",
       " 416: 'Pascal',\n",
       " 417: 'Patternlab',\n",
       " 418: 'Payments',\n",
       " 419: 'Pentaho Data Integration',\n",
       " 420: 'Perforce',\n",
       " 421: 'Perl',\n",
       " 422: 'Personas',\n",
       " 423: 'Photo Paint',\n",
       " 424: 'Photopea',\n",
       " 425: 'PhpStorm',\n",
       " 426: 'Phyton /Jython',\n",
       " 427: 'Pimcore',\n",
       " 428: 'Plexus',\n",
       " 429: 'PlumTree',\n",
       " 430: 'PocketPC',\n",
       " 431: 'Polarion',\n",
       " 432: 'Polnisch',\n",
       " 433: 'Portlet API',\n",
       " 434: 'Poseidon',\n",
       " 435: 'Postfix',\n",
       " 436: 'PostgreSQL',\n",
       " 437: 'Postman',\n",
       " 438: 'Power BI',\n",
       " 439: 'PowerApps',\n",
       " 440: 'PowerAutomate',\n",
       " 441: 'PowerShell',\n",
       " 442: 'Principle',\n",
       " 443: 'Product Owner',\n",
       " 444: 'Produkt Design',\n",
       " 445: 'Produktkonfigurator',\n",
       " 446: 'Produktstrategie',\n",
       " 447: 'Professional Scrum Master (PSM)',\n",
       " 448: 'Professional Scrum Product Owner (PSPO)',\n",
       " 449: 'Projektmanagement',\n",
       " 450: 'Promotion / Drools Engine',\n",
       " 451: 'Prototyping',\n",
       " 452: 'ProxySQL',\n",
       " 453: 'Prozessmanagement',\n",
       " 454: 'Public Key Infrastructures (PKI)',\n",
       " 455: 'Pulumi',\n",
       " 456: 'Puma',\n",
       " 457: 'Python',\n",
       " 458: 'Qlik 12 Certified Business Analyst',\n",
       " 459: 'Qlik 12 Certified Data Architekt',\n",
       " 460: 'Qlik 12 Certified System Administrator',\n",
       " 461: 'QlikView / QlikSense',\n",
       " 462: 'Qt QML',\n",
       " 463: 'Qualitätsmanagement',\n",
       " 464: 'Quark Express',\n",
       " 465: 'Quarkus',\n",
       " 466: 'RDP',\n",
       " 467: 'REST',\n",
       " 468: 'RFC',\n",
       " 469: 'RMI',\n",
       " 470: 'RPG',\n",
       " 471: 'Rabbitmq',\n",
       " 472: 'Raspberry Pi',\n",
       " 473: 'Rational',\n",
       " 474: 'Rational Rose',\n",
       " 475: 'Rational System Architect',\n",
       " 476: 'Rational Unified Process (RUP)',\n",
       " 477: 'React',\n",
       " 478: 'React Native',\n",
       " 479: 'React Testing Library',\n",
       " 480: 'RedDot',\n",
       " 481: 'RedHat Linux',\n",
       " 482: 'Redaxo',\n",
       " 483: 'Redis',\n",
       " 484: 'Redmine',\n",
       " 485: 'Redux',\n",
       " 486: 'Requirements Engineering',\n",
       " 487: 'Responsive Webdesign',\n",
       " 488: 'Ruby',\n",
       " 489: 'Russisch',\n",
       " 490: 'Rust',\n",
       " 491: 'RxJS',\n",
       " 492: 'SAP',\n",
       " 493: 'SAP Adaptive Server Enterprise 16.0',\n",
       " 494: 'SAP Business Information Warehouse',\n",
       " 495: 'SAP Cloud Platform Integration (SCPI)',\n",
       " 496: 'SAP Commerce 6.x',\n",
       " 497: 'SAP Commerce Cloud V2',\n",
       " 498: 'SAP Commerce Platform Basics',\n",
       " 499: 'SAP Consulting',\n",
       " 500: 'SAP DB',\n",
       " 501: 'SAP ERP Anbindung',\n",
       " 502: 'SAP Identity Management 8.0',\n",
       " 503: 'SAP NWDI',\n",
       " 504: 'SAP NWDS',\n",
       " 505: 'SAP OCI / B2B PunchOut',\n",
       " 506: 'SAP S4/Hana - Cloud Anbindung',\n",
       " 507: 'SAP Variant Configuration and Pricing Anbindung',\n",
       " 508: 'SCRUM',\n",
       " 509: 'SCSS',\n",
       " 510: 'SEO Tool Anbindung',\n",
       " 511: 'SOAP',\n",
       " 512: 'SPSS',\n",
       " 513: 'SQL',\n",
       " 514: 'SQL-Scripte',\n",
       " 515: 'SQLBase',\n",
       " 516: 'SSL',\n",
       " 517: 'SSO Anbindung',\n",
       " 518: 'SUSE Linux',\n",
       " 519: 'SVG',\n",
       " 520: 'SWT',\n",
       " 521: 'Sass',\n",
       " 522: 'Sass/SCSS',\n",
       " 523: 'Schwedisch',\n",
       " 524: 'Screendesign',\n",
       " 525: 'Security',\n",
       " 526: 'Selectica',\n",
       " 527: 'SendMail',\n",
       " 528: 'Service Oriented Architecture (SOA)',\n",
       " 529: 'Servlet/JSP',\n",
       " 530: 'SharePoint',\n",
       " 531: 'Sharepoint Entwicklung',\n",
       " 532: 'SharpDevelop',\n",
       " 533: 'ShellScripting',\n",
       " 534: 'Shockwave',\n",
       " 535: 'Shopware',\n",
       " 536: 'Siemens SPS',\n",
       " 537: 'Silverlight',\n",
       " 538: 'Silverstripe',\n",
       " 539: 'Sitecore',\n",
       " 540: 'Six Sigma',\n",
       " 541: 'SixCMS',\n",
       " 542: 'Sketch',\n",
       " 543: 'Sketchnotes',\n",
       " 544: 'Sketchup',\n",
       " 545: 'Smalltalk',\n",
       " 546: 'SmartHome',\n",
       " 547: 'Smartedit',\n",
       " 548: 'Sofon',\n",
       " 549: 'Softwarearchitektur',\n",
       " 550: 'Softwaredesign/-architektur',\n",
       " 551: 'Softwareeinführung',\n",
       " 552: 'Softwaretests',\n",
       " 553: 'Solr',\n",
       " 554: 'SonarQube',\n",
       " 555: 'Sonatype Nexus',\n",
       " 556: 'Sonstiges (Freitextfeld)',\n",
       " 557: 'Spanisch',\n",
       " 558: 'Spartacus',\n",
       " 559: 'Sport',\n",
       " 560: 'Spring',\n",
       " 561: 'Spring Boot',\n",
       " 562: 'Spring Data JPA',\n",
       " 563: 'Spring-Batch',\n",
       " 564: 'Spring-Integration',\n",
       " 565: 'Spring-JPA',\n",
       " 566: 'Spring.NET',\n",
       " 567: 'Static Site Generierung',\n",
       " 568: 'Statische Codeanalyse',\n",
       " 569: 'Stencil',\n",
       " 570: 'Storefront',\n",
       " 571: 'Storybook',\n",
       " 572: 'Struts (bis Version 1.3)',\n",
       " 573: 'Struts 2',\n",
       " 574: 'Studentisches Praktikum',\n",
       " 575: 'StyleReport',\n",
       " 576: 'Styled Components',\n",
       " 577: 'Stylelint',\n",
       " 578: 'SublimeText',\n",
       " 579: 'Subversion',\n",
       " 580: 'Sun Java Studio',\n",
       " 581: 'Sun Solaris',\n",
       " 582: 'Svelte',\n",
       " 583: 'Swift',\n",
       " 584: 'Swing',\n",
       " 585: 'Swing/AWT',\n",
       " 586: 'Sybase',\n",
       " 587: 'Symbian',\n",
       " 588: 'Symfony',\n",
       " 589: 'Systemaufstellung',\n",
       " 590: 'T-SQL',\n",
       " 591: 'TCP/IP',\n",
       " 592: 'TOAD',\n",
       " 593: 'TYPO3',\n",
       " 594: 'TYPO3 Generalist',\n",
       " 595: 'Tableau Datenvisualisierung - Tableau Datenanalyse Tool',\n",
       " 596: 'Tailwind CSS ',\n",
       " 597: 'Team Developer',\n",
       " 598: 'Team Foundation Server (TF Server)',\n",
       " 599: 'TeamCity',\n",
       " 600: 'TeamSite',\n",
       " 601: 'Teamviewer',\n",
       " 602: 'Terminalserver',\n",
       " 603: 'Terraform',\n",
       " 604: 'Test Driven Development (TDD)',\n",
       " 605: 'TestNG',\n",
       " 606: 'Testautomatisierung',\n",
       " 607: 'Testing Library',\n",
       " 608: 'Tipko',\n",
       " 609: 'Tomcat',\n",
       " 610: 'TopLink',\n",
       " 611: 'Tourismus',\n",
       " 612: 'Touristik',\n",
       " 613: 'Trac',\n",
       " 614: 'Twig',\n",
       " 615: 'TypeScript',\n",
       " 616: 'TypoScript',\n",
       " 617: 'Typography',\n",
       " 618: 'Türkisch',\n",
       " 619: 'UI Design',\n",
       " 620: 'UI-Automation',\n",
       " 621: 'UML',\n",
       " 622: 'UWP',\n",
       " 623: 'UX',\n",
       " 624: 'UX Beratung',\n",
       " 625: 'UX Strategie',\n",
       " 626: 'UX/UI',\n",
       " 627: 'Ubuntu',\n",
       " 628: 'Ultra Edit',\n",
       " 629: 'UltraDev',\n",
       " 630: 'Unipark',\n",
       " 631: 'Unit Tests (Komponententests)',\n",
       " 632: 'Unity',\n",
       " 633: 'Usability-Tests',\n",
       " 634: 'User Experience',\n",
       " 635: 'User Research',\n",
       " 636: 'User Tests',\n",
       " 637: 'V-Modell',\n",
       " 638: 'V-Modell XT',\n",
       " 639: 'VB.NET',\n",
       " 640: 'VB/VBA',\n",
       " 641: 'Vanilla JS',\n",
       " 642: 'Velocity',\n",
       " 643: 'Versicherungen',\n",
       " 644: 'Vimeo Psalm',\n",
       " 645: 'Virtual Reality',\n",
       " 646: 'Visual Objects',\n",
       " 647: 'Visual Source Safe',\n",
       " 648: 'Visual Studio',\n",
       " 649: 'Voice Interfaces',\n",
       " 650: 'Vue.js',\n",
       " 651: 'WCMS',\n",
       " 652: 'WML',\n",
       " 653: 'WSUS',\n",
       " 654: 'Wasserfallmodel',\n",
       " 655: 'Web Components',\n",
       " 656: 'Web Security',\n",
       " 657: 'WebDynpro',\n",
       " 658: 'WebObjects',\n",
       " 659: 'WebServices',\n",
       " 660: 'WebStorm',\n",
       " 661: 'Weblogic',\n",
       " 662: 'Webpack',\n",
       " 663: 'Wildfly',\n",
       " 664: 'WinUI',\n",
       " 665: 'Windows',\n",
       " 666: 'Windows 10',\n",
       " 667: 'Windows 11',\n",
       " 668: 'Windows 7',\n",
       " 669: 'Windows 8',\n",
       " 670: 'Windows Communication Foundation (WCF)',\n",
       " 671: 'Windows Embedded',\n",
       " 672: 'Windows Forms',\n",
       " 673: 'Windows Identity Foundation (WIF)',\n",
       " 674: 'Windows NT/2000/XP',\n",
       " 675: 'Windows Phone 7',\n",
       " 676: 'Windows Presentation Foundation (WPF)',\n",
       " 677: 'Windows Printserver',\n",
       " 678: 'Windows Server 2003',\n",
       " 679: 'Windows Server 2008',\n",
       " 680: 'Windows Server 2008 R2 /2012',\n",
       " 681: 'Windows Server 2012 R2',\n",
       " 682: 'Windows Small Business Server',\n",
       " 683: 'Windows Vista',\n",
       " 684: 'Windows Workflow Foundation (WF)',\n",
       " 685: 'WordPress',\n",
       " 686: 'Workbench',\n",
       " 687: 'X11/XWindows',\n",
       " 688: 'XML/XSL',\n",
       " 689: 'XSQL',\n",
       " 690: 'Xamarin',\n",
       " 691: 'Xcode',\n",
       " 692: 'Xerces',\n",
       " 693: 'YAML',\n",
       " 694: 'Yii',\n",
       " 695: 'Zend ',\n",
       " 696: 'Zeplin',\n",
       " 697: 'alphaplan',\n",
       " 698: 'amavis',\n",
       " 699: 'arc42',\n",
       " 700: 'ePages',\n",
       " 701: 'f-prot',\n",
       " 702: 'ftp-proxy',\n",
       " 703: 'gdscript',\n",
       " 704: 'gpg',\n",
       " 705: 'gradle',\n",
       " 706: 'haml',\n",
       " 707: 'helm',\n",
       " 708: 'iOS',\n",
       " 709: 'imp',\n",
       " 710: 'inubit BPM-Suite',\n",
       " 711: 'inuitcss - responsive Frontend-Framework',\n",
       " 712: 'jQuery',\n",
       " 713: 'knockout',\n",
       " 714: 'lodash',\n",
       " 715: 'mithril',\n",
       " 716: 'nginx',\n",
       " 717: 'nopCommerce',\n",
       " 718: 'npm',\n",
       " 719: 'nx Workspace ',\n",
       " 720: 'osCommerce',\n",
       " 721: 'preact',\n",
       " 722: 'prototype',\n",
       " 723: 'pycharm',\n",
       " 724: 'ramda.js',\n",
       " 725: 'ranorex',\n",
       " 726: 'samba',\n",
       " 727: 'script.aculo.us',\n",
       " 728: 'varnish',\n",
       " 729: 'visual paradigm',\n",
       " 730: 'vnc',\n",
       " 731: 'vs code',\n",
       " 732: 'xHTML',\n",
       " 733: 'xtCommerce'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_skills_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>score</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.NET Framework</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>.NET Frameworks und Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Windows Forms</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>.NET Frameworks und Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASP.NET WebAPI</td>\n",
       "      <td>0.957794</td>\n",
       "      <td>.NET Frameworks und Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASP.NET MVC-Framework</td>\n",
       "      <td>0.938920</td>\n",
       "      <td>.NET Frameworks und Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LINQ</td>\n",
       "      <td>0.932838</td>\n",
       "      <td>.NET Frameworks und Tools</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   skill     score                   category\n",
       "0         .NET Framework  1.000000  .NET Frameworks und Tools\n",
       "1          Windows Forms  0.963333  .NET Frameworks und Tools\n",
       "2         ASP.NET WebAPI  0.957794  .NET Frameworks und Tools\n",
       "3  ASP.NET MVC-Framework  0.938920  .NET Frameworks und Tools\n",
       "4                   LINQ  0.932838  .NET Frameworks und Tools"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_id, sim = model.similar_items(2, N=5)\n",
    "# display the results using pandas for nicer formatting\n",
    "similarity_df  = pd.DataFrame({\"skill\": data_skills.columns[skill_id], \"score\": sim})\n",
    "similarity_df.merge(data_categories, how = \"left\", left_on = \"skill\", right_on = \"skill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_skills = {\n",
    "                \"Windows 11\":1,\n",
    "                \"Englisch\":1,\n",
    "                \"Chinesisch (Mandarin)\":1,\n",
    "                \"Python\":1,\n",
    "                \"MATLAB\":1,\n",
    "                \"Java\":1,\n",
    "                \"MySQL\":1,\n",
    "                \"SQLBase\":1,\n",
    "                \"Microsoft SQL Server\":1,\n",
    "                \"Google Cloud Platform\":1,\n",
    "                \"MongoDB\":1,\n",
    "                \"JSON\":1,\n",
    "                \"Docker\":1,\n",
    "                \"Statische Codeanalyse\": 1,\n",
    "                \"Power BI\":1,\n",
    "                \"Postman\":1,\n",
    "                \"PowerShell\":1,\n",
    "                \"Github actions\":1\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id_list = list(new_skills.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ids</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>247</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_ids  score\n",
       "0       273    1.0\n",
       "1       247    1.0\n",
       "2        62    1.0\n",
       "3         9    1.0\n",
       "4         8    1.0\n",
       "5         7    1.0\n",
       "6         6    1.0\n",
       "7         5    1.0\n",
       "8         4    1.0\n",
       "9         3    1.0"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids_, sim = model.similar_users(0, N=10)\n",
    "# display the results using pandas for nicer formatting\n",
    "similarity_df  = pd.DataFrame({\"user_ids\": data_skills.index[user_ids_], \"score\": sim})\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_cv_implicit(data, algorithm, param_grid):\n",
    "    df_list = []\n",
    "    df_result = pd.DataFrame()\n",
    "\n",
    "    data_list, df = normalizer(data, param_grid_bm25)\n",
    "\n",
    "    \n",
    "    for b,d in enumerate(data_list):\n",
    "        df1 = df.loc[b].to_frame().T\n",
    "        data_rep = d\n",
    "\n",
    "        keys, values = zip(*param_grid.items())\n",
    "        for v in itertools.product(*values):\n",
    "            \n",
    "            #############\n",
    "            # This for loop produces every possible combination of the hyperparameters within a dictonary\n",
    "            #############\n",
    "            params = dict(zip(keys, v))\n",
    "            this_model = copy.deepcopy(algorithm)\n",
    "            df2 = pd.DataFrame()\n",
    "            df2 = pd.DataFrame(params, index =  [b])\n",
    "    \n",
    "            \n",
    "\n",
    "            for k, v in params.items():\n",
    "                #############\n",
    "                # This loop unpacks the diconary by each parameter and initiates the model for each hpyerparameter of the corresponding dictonary\n",
    "                #############\n",
    "                setattr(this_model, k, v)\n",
    "\n",
    "            ############\n",
    "            # lists to store the results after each train_test_split under different random seed (c.p)\n",
    "            ############\n",
    "            p_train_test_results = []\n",
    "            map_train_test_results = []\n",
    "            ndcg_train_test_results = []\n",
    "\n",
    "\n",
    "            for r_seed in range(0,5):\n",
    "                #############\n",
    "                # Initiate the train_test_split\n",
    "                #############\n",
    "                train_mat, test_mat = implicit.evaluation.train_test_split(data_rep, train_percentage =  0.8, random_state = r_seed)\n",
    "                this_model.fit(train_mat,show_progress=False)\n",
    "\n",
    "                #############\n",
    "                # measure evaluation metrixs for each possible hyperparameter combination\n",
    "                #############\n",
    "                p_at_k =  precision_at_k(this_model, train_user_items=train_mat, test_user_items=test_mat, K=5 ,show_progress=False)\n",
    "                map_at_k = mean_average_precision_at_k(this_model, train_user_items=train_mat, test_user_items=test_mat, K=5,show_progress=False)\n",
    "                var_ndcg_at_k = ndcg_at_k(this_model, train_user_items=train_mat, test_user_items=test_mat, K=5,show_progress=False)\n",
    "\n",
    "\n",
    "                #############\n",
    "                # To list\n",
    "                #############\n",
    "                p_train_test_results.append(p_at_k)\n",
    "                map_train_test_results.append(map_at_k)\n",
    "                ndcg_train_test_results.append(var_ndcg_at_k)\n",
    "\n",
    "            #############\n",
    "            # Create columns to store the scores for each hyperparameter combination after 5 different train_test_splits\n",
    "            #############\n",
    "            df2[\"precision_at_k\"] = np.mean(p_train_test_results)\n",
    "            df2[\"map_at_k\"]  = np.mean(map_train_test_results)\n",
    "            df2[\"ndcg_at_k\"] = np.mean(ndcg_train_test_results)\n",
    "\n",
    "            df_result = df1.merge(df2, left_index=True, right_index=True)\n",
    "            df_list.append(df_result)\n",
    "    \n",
    "    return pd.concat(df_list).reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid= [0,1]\n",
    "\n",
    "def get_recommendations (userids, user_items_mat_train,full_data_mat ,items_to_exclude = None ,n = 5):\n",
    "    df_list = []\n",
    "\n",
    "    if items_to_exclude is not None:\n",
    "        items_to_exclude  = get_key_from_value(dict_skills_id,items_to_exclude)\n",
    "\n",
    "    for u in userids:\n",
    "        \n",
    "        \n",
    "        #############\n",
    "        # Do recommendations for every user in the list. The known items are in the matrix the model was trained on\n",
    "        #############\n",
    "        skill_ids, scores  = model.recommend(u, user_items= user_items_mat_train[u], N = n , filter_already_liked_items=True, filter_items = items_to_exclude)\n",
    "        recommendations_df = pd.DataFrame({ \"skill\": SKILLS, \"score\": scores, \"already_liked\": np.in1d(skill_ids, user_items_mat_train.tocsr()[u].indices)})\n",
    "        recommendations_df[\"user_id\"] = [u] * len(recommendations_df)\n",
    "        recommendations_df = recommendations_df.rename(columns = {\"already_liked\": \"already_liked_in_train\"})\n",
    "\n",
    "        #############\n",
    "        # Get all known skills for each user by indexing the full data matrix\n",
    "        #############\n",
    "        data_best_user_id = pd.DataFrame.sparse.from_spmatrix(data = full_data_mat.tocsr()[u],columns=data_skills.columns).T.reset_index().rename(columns = {\"index\": \"skill\",0: \"rating\"}).sort_values(by = \"rating\", ascending = False)\n",
    "        data_best_user_id[\"user_id\"] = [u] * len(data_best_user_id)\n",
    "      \n",
    "        #############\n",
    "        # Merge both df in order to see, if the recommended skills are the skills, which the user already knows, but were left out in the trainings data\n",
    "        #############\n",
    "        recommendations_df = recommendations_df.merge(data_best_user_id, on = [\"skill\",\"user_id\"], how = \"left\").rename(columns = {\"rating\": \"rating_in_original\"})\n",
    "        \n",
    "\n",
    "        #############\n",
    "        # Merge the category information to the recommendations\n",
    "        #############\n",
    "        recommendations_df = recommendations_df.merge(data_categories, on = \"skill\", how = \"left\")\n",
    "        recommendations_df.set_index(\"user_id\", inplace = True)\n",
    "        df_list.append(recommendations_df)\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>score</th>\n",
       "      <th>already_liked_in_train</th>\n",
       "      <th>rating_in_original</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCRUM</td>\n",
       "      <td>0.691310</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Projektmanagement / Vorgehensmodelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unit Tests (Komponententests)</td>\n",
       "      <td>0.664733</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Methoden und Praktiken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XML/XSL</td>\n",
       "      <td>0.624774</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Standards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSS</td>\n",
       "      <td>0.605857</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Webentwicklung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSS</td>\n",
       "      <td>0.605857</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Programmiersprachen / Scriptsprachen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REST</td>\n",
       "      <td>0.578240</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Standards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dokumentation</td>\n",
       "      <td>0.567920</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Einsatzfelder / Erfahrungen / Schwerpunkte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jQuery</td>\n",
       "      <td>0.562962</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Webentwicklung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dependency Injection</td>\n",
       "      <td>0.553882</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Methoden und Praktiken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Softwaredesign/-architektur</td>\n",
       "      <td>0.552909</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Einsatzfelder / Erfahrungen / Schwerpunkte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOAP</td>\n",
       "      <td>0.543369</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Standards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test Driven Development (TDD)</td>\n",
       "      <td>0.666901</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Methoden und Praktiken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCRUM</td>\n",
       "      <td>0.663056</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Projektmanagement / Vorgehensmodelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Implementierung</td>\n",
       "      <td>0.608923</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Einsatzfelder / Erfahrungen / Schwerpunkte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dokumentation</td>\n",
       "      <td>0.544709</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Einsatzfelder / Erfahrungen / Schwerpunkte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Softwaredesign/-architektur</td>\n",
       "      <td>0.530311</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Einsatzfelder / Erfahrungen / Schwerpunkte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOAP</td>\n",
       "      <td>0.521161</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Standards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apache</td>\n",
       "      <td>0.494498</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Applikationsserver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Softwaretests</td>\n",
       "      <td>0.490247</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Einsatzfelder / Erfahrungen / Schwerpunkte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Visual Studio</td>\n",
       "      <td>0.484340</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Umgebungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C/C++</td>\n",
       "      <td>0.458930</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Programmiersprachen / Scriptsprachen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 skill     score  already_liked_in_train  \\\n",
       "user_id                                                                    \n",
       "0                                SCRUM  0.691310                   False   \n",
       "0        Unit Tests (Komponententests)  0.664733                   False   \n",
       "0                              XML/XSL  0.624774                   False   \n",
       "0                                  CSS  0.605857                   False   \n",
       "0                                  CSS  0.605857                   False   \n",
       "0                                 REST  0.578240                   False   \n",
       "0                        Dokumentation  0.567920                   False   \n",
       "0                               jQuery  0.562962                   False   \n",
       "0                 Dependency Injection  0.553882                   False   \n",
       "0          Softwaredesign/-architektur  0.552909                   False   \n",
       "0                                 SOAP  0.543369                   False   \n",
       "1        Test Driven Development (TDD)  0.666901                   False   \n",
       "1                                SCRUM  0.663056                   False   \n",
       "1                      Implementierung  0.608923                   False   \n",
       "1                        Dokumentation  0.544709                   False   \n",
       "1          Softwaredesign/-architektur  0.530311                   False   \n",
       "1                                 SOAP  0.521161                   False   \n",
       "1                               Apache  0.494498                   False   \n",
       "1                        Softwaretests  0.490247                   False   \n",
       "1                        Visual Studio  0.484340                   False   \n",
       "1                                C/C++  0.458930                   False   \n",
       "\n",
       "         rating_in_original                                    category  \n",
       "user_id                                                                  \n",
       "0                         1        Projektmanagement / Vorgehensmodelle  \n",
       "0                         1                      Methoden und Praktiken  \n",
       "0                         0                                   Standards  \n",
       "0                         0                              Webentwicklung  \n",
       "0                         0        Programmiersprachen / Scriptsprachen  \n",
       "0                         1                                   Standards  \n",
       "0                         0  Einsatzfelder / Erfahrungen / Schwerpunkte  \n",
       "0                         0                              Webentwicklung  \n",
       "0                         1                      Methoden und Praktiken  \n",
       "0                         0  Einsatzfelder / Erfahrungen / Schwerpunkte  \n",
       "0                         0                                   Standards  \n",
       "1                         1                      Methoden und Praktiken  \n",
       "1                         0        Projektmanagement / Vorgehensmodelle  \n",
       "1                         1  Einsatzfelder / Erfahrungen / Schwerpunkte  \n",
       "1                         0  Einsatzfelder / Erfahrungen / Schwerpunkte  \n",
       "1                         1  Einsatzfelder / Erfahrungen / Schwerpunkte  \n",
       "1                         0                                   Standards  \n",
       "1                         0                          Applikationsserver  \n",
       "1                         1  Einsatzfelder / Erfahrungen / Schwerpunkte  \n",
       "1                         1                                  Umgebungen  \n",
       "1                         0        Programmiersprachen / Scriptsprachen  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommendations_df = get_recommendations(userid, train_mat,best_data,n = 10,item_to_exclude= [\"MySQL\"])\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_representations</th>\n",
       "      <th>K1</th>\n",
       "      <th>B</th>\n",
       "      <th>factors</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iterations</th>\n",
       "      <th>alpha</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>map_at_k</th>\n",
       "      <th>ndcg_at_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459071</td>\n",
       "      <td>0.357035</td>\n",
       "      <td>0.444635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.488633</td>\n",
       "      <td>0.385132</td>\n",
       "      <td>0.472573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455082</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.438058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450738</td>\n",
       "      <td>0.350056</td>\n",
       "      <td>0.436405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325121</td>\n",
       "      <td>0.230505</td>\n",
       "      <td>0.306353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378964</td>\n",
       "      <td>0.273204</td>\n",
       "      <td>0.358962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bm25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092194</td>\n",
       "      <td>0.044148</td>\n",
       "      <td>0.079159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bm25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195050</td>\n",
       "      <td>0.122778</td>\n",
       "      <td>0.187092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_representations   K1    B  factors  regularization  iterations  alpha  \\\n",
       "0                  Raw  NaN  NaN        1           0.005          15      1   \n",
       "1                  Raw  NaN  NaN        2           0.005          15      1   \n",
       "2           Normalized  NaN  NaN        1           0.005          15      1   \n",
       "3           Normalized  NaN  NaN        2           0.005          15      1   \n",
       "4                tfidf  NaN  NaN        1           0.005          15      1   \n",
       "5                tfidf  NaN  NaN        2           0.005          15      1   \n",
       "6                 bm25  3.0  0.6        1           0.005          15      1   \n",
       "7                 bm25  3.0  0.6        2           0.005          15      1   \n",
       "\n",
       "   precision_at_k  map_at_k  ndcg_at_k  \n",
       "0        0.459071  0.357035   0.444635  \n",
       "1        0.488633  0.385132   0.472573  \n",
       "2        0.455082  0.351404   0.438058  \n",
       "3        0.450738  0.350056   0.436405  \n",
       "4        0.325121  0.230505   0.306353  \n",
       "5        0.378964  0.273204   0.358962  \n",
       "6        0.092194  0.044148   0.079159  \n",
       "7        0.195050  0.122778   0.187092  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_als= gridsearch_cv_implicit(data_skills_csr, algorithm = implicit.als.AlternatingLeastSquares(random_state = 42),param_grid =  als_grid)\n",
    "results_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>score</th>\n",
       "      <th>already_liked_in_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCRUM</td>\n",
       "      <td>0.892121</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unit Tests (Komponententests)</td>\n",
       "      <td>0.774384</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MySQL</td>\n",
       "      <td>0.772703</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dependency Injection</td>\n",
       "      <td>0.659050</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REST</td>\n",
       "      <td>0.650433</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           skill     score  already_liked_in_train\n",
       "0                          SCRUM  0.892121                   False\n",
       "1  Unit Tests (Komponententests)  0.774384                   False\n",
       "2                          MySQL  0.772703                   False\n",
       "3           Dependency Injection  0.659050                   False\n",
       "4                           REST  0.650433                   False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skill_ids, scores  = model.recommend(0, user_items= train_mat[0], N = 5 , filter_already_liked_items=True, recalculate_user=True)\n",
    "recommendations_df = pd.DataFrame({ \"skill\": matrix.columns[skill_ids], \"score\": scores, \"already_liked\": np.in1d(skill_ids, train_mat.tocsr()[0].indices)})\n",
    "recommendations_df = recommendations_df.rename(columns = {\"already_liked\": \"already_liked_in_train\"})\n",
    "recommendations_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "952d20126e355007ee7ec6cf97a37e6210c6c2e8a70e82c0bc649e118c2b0b1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
